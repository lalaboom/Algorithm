{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import print_function\n",
    "# import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,BatchNormalization,Dropout\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from collections import Counter\n",
    "# %matplotlib inline\n",
    "np.random.seed(1671) # for reproducibility\n",
    "# from help_function import LoadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SaleID', 'bodyType', 'brand', 'brand_type', 'city', 'creatDate',\n",
       "       'fuelType', 'gearbox', 'is_train', 'kilometer', 'model', 'name',\n",
       "       'notRepairedDamage', 'power', 'price', 'regDate', 'regionCode', 'v_0',\n",
       "       'v_1', 'v_10', 'v_11', 'v_12', 'v_13', 'v_14', 'v_2', 'v_3', 'v_4',\n",
       "       'v_5', 'v_6', 'v_7', 'v_8', 'v_9', 'regDate_year', 'creatDate_year',\n",
       "       'during_month', 'during_year', 'brand_amount', 'brand_price_average',\n",
       "       'brand_price_max', 'brand_price_median', 'brand_price_min',\n",
       "       'brand_price_std', 'brand_price_sum', 'brand_type_amount',\n",
       "       'brand_type_average', 'brand_type_max', 'brand_type_median',\n",
       "       'brand_type_min', 'brand_type_std', 'brand_type_sum', 'city_amount',\n",
       "       'city_average', 'city_max', 'city_median', 'city_min', 'city_std',\n",
       "       'city_sum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>brand</th>\n",
       "      <th>brand_type</th>\n",
       "      <th>city</th>\n",
       "      <th>creatDate</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>is_train</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>...</th>\n",
       "      <th>brand_type_min</th>\n",
       "      <th>brand_type_std</th>\n",
       "      <th>brand_type_sum</th>\n",
       "      <th>city_amount</th>\n",
       "      <th>city_average</th>\n",
       "      <th>city_max</th>\n",
       "      <th>city_median</th>\n",
       "      <th>city_min</th>\n",
       "      <th>city_std</th>\n",
       "      <th>city_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>601.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2707.072478</td>\n",
       "      <td>7868239.0</td>\n",
       "      <td>3521.0</td>\n",
       "      <td>6176.86</td>\n",
       "      <td>73900.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7397.792986</td>\n",
       "      <td>21754915.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>102.0</td>\n",
       "      <td>43</td>\n",
       "      <td>2016-03-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7802.604925</td>\n",
       "      <td>46879429.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>5449.87</td>\n",
       "      <td>42700.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6140.251744</td>\n",
       "      <td>8027664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>28</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4940.333864</td>\n",
       "      <td>7390310.0</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>5546.22</td>\n",
       "      <td>63999.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6613.670703</td>\n",
       "      <td>12201689.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-03-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6962.900499</td>\n",
       "      <td>37761446.0</td>\n",
       "      <td>3905.0</td>\n",
       "      <td>6226.05</td>\n",
       "      <td>89950.0</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7120.912973</td>\n",
       "      <td>24318967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>501.0</td>\n",
       "      <td>69</td>\n",
       "      <td>2016-03-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2045.355745</td>\n",
       "      <td>4016555.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>5757.79</td>\n",
       "      <td>48500.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6733.317718</td>\n",
       "      <td>3086176.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SaleID  bodyType  brand  brand_type  city   creatDate  fuelType  gearbox  \\\n",
       "0       0       1.0      6       601.0    10  2016-04-04       0.0      0.0   \n",
       "1       1       2.0      1       102.0    43  2016-03-09       0.0      0.0   \n",
       "2       2       1.0     15      1501.0    28  2016-04-02       0.0      0.0   \n",
       "3       3       0.0     10      1000.0     4  2016-03-12       0.0      1.0   \n",
       "4       4       1.0      5       501.0    69  2016-03-13       0.0      0.0   \n",
       "\n",
       "   is_train  kilometer  ...  brand_type_min  brand_type_std brand_type_sum  \\\n",
       "0         1       12.5  ...            30.0     2707.072478      7868239.0   \n",
       "1         1       15.0  ...           100.0     7802.604925     46879429.0   \n",
       "2         1       12.5  ...           100.0     4940.333864      7390310.0   \n",
       "3         1       15.0  ...            35.0     6962.900499     37761446.0   \n",
       "4         1        5.0  ...            50.0     2045.355745      4016555.0   \n",
       "\n",
       "   city_amount  city_average city_max  city_median  city_min     city_std  \\\n",
       "0       3521.0       6176.86  73900.0       3500.0      20.0  7397.792986   \n",
       "1       1472.0       5449.87  42700.0       3200.0      20.0  6140.251744   \n",
       "2       2199.0       5546.22  63999.0       3200.0      30.0  6613.670703   \n",
       "3       3905.0       6226.05  89950.0       3700.0      20.0  7120.912973   \n",
       "4        535.0       5757.79  48500.0       3450.0      50.0  6733.317718   \n",
       "\n",
       "     city_sum  \n",
       "0  21754915.0  \n",
       "1   8027664.0  \n",
       "2  12201689.0  \n",
       "3  24318967.0  \n",
       "4   3086176.0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"nn_data.csv\")\n",
    "\n",
    "\n",
    "train_data = data[data['is_train']==1]\n",
    "test_data = data[data['is_train'] ==0]\n",
    "#test = test[test['mt'] <25]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199037, 57)\n",
      "(149037, 57)\n",
      "(50000, 57)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor item in cate_feats:\\n    print(item)\\n    data[item] = LabelEncoder().fit_transform(data[item])\\n    item_dummies = pd.get_dummies(data[item])\\n    item_dummies.columns = [item + str(i + 1) for i in range(item_dummies.shape[1])]\\n    data = pd.concat([data, item_dummies], axis=1)\\ndata.drop(cate_feature,axis=1,inplace=True)\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.read_csv(\"nn_data1010.csv\")\n",
    "\n",
    "# del data['forecastVolum'],data['pred_label']\n",
    "# train_data = data[data['mt']<25]\n",
    "# test = data[data['mt']>=25]\n",
    "# train_data.head()\n",
    "\n",
    "\n",
    "## load data\n",
    "# train_data = pd.read_csv('data/train.csv')\n",
    "# test_data = pd.read_csv('data/test.csv')\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "classes = 1\n",
    "\n",
    "## category feature one_hot\n",
    "test_data['price'] = -1\n",
    "\n",
    "\n",
    "num_feats = ['power', 'kilometer', 'during_month',  'during_year','brand_amount',\n",
    "       'brand_price_average', 'brand_price_max', 'brand_price_median',\n",
    "       'brand_price_min', 'brand_price_std', 'brand_price_sum','city',\n",
    "       'brand_type_amount', 'brand_type_average', 'brand_type_max',\n",
    "       'brand_type_median', 'brand_type_min', 'brand_type_std','regDate_year', \n",
    "       'brand_type_sum',\n",
    "       'city_amount', \n",
    "       'city_average','city_median', 'city_min', 'city_std',\n",
    "       'city_sum',\n",
    "       'v_0', 'v_1', 'v_2', 'v_3', 'v_4', 'v_9','v_5',\n",
    "       'v_8',  'v_10', 'v_11', 'v_12', 'v_13','v_14' ] # 'v_6', 'v_7','v_9', 'v_5','v_6','v_11', 'city_max', \n",
    "\n",
    "cate_feats = ['model', 'brand', 'bodyType', 'fuelType','name','gearbox',\n",
    "             'notRepairedDamage', 'regionCode','brand_type']\n",
    "\n",
    "feats = cate_feats+num_feats\n",
    "\n",
    "for item in cate_feats:#\n",
    "    data[item] = LabelEncoder().fit_transform(data[item])\n",
    "    \n",
    "train_data = data[data['is_train']==1]\n",
    "test_data = data[data['is_train'] ==0]    \n",
    "print(data.shape)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "'''\n",
    "for item in cate_feats:\n",
    "    print(item)\n",
    "    data[item] = LabelEncoder().fit_transform(data[item])\n",
    "    item_dummies = pd.get_dummies(data[item])\n",
    "    item_dummies.columns = [item + str(i + 1) for i in range(item_dummies.shape[1])]\n",
    "    data = pd.concat([data, item_dummies], axis=1)\n",
    "data.drop(cate_feature,axis=1,inplace=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>brand</th>\n",
       "      <th>brand_type</th>\n",
       "      <th>city</th>\n",
       "      <th>creatDate</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>is_train</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>...</th>\n",
       "      <th>brand_type_min</th>\n",
       "      <th>brand_type_std</th>\n",
       "      <th>brand_type_sum</th>\n",
       "      <th>city_amount</th>\n",
       "      <th>city_average</th>\n",
       "      <th>city_max</th>\n",
       "      <th>city_median</th>\n",
       "      <th>city_min</th>\n",
       "      <th>city_std</th>\n",
       "      <th>city_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2707.072478</td>\n",
       "      <td>7868239.0</td>\n",
       "      <td>3521.0</td>\n",
       "      <td>6176.86</td>\n",
       "      <td>73900.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7397.792986</td>\n",
       "      <td>21754915.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "      <td>2016-03-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7802.604925</td>\n",
       "      <td>46879429.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>5449.87</td>\n",
       "      <td>42700.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6140.251744</td>\n",
       "      <td>8027664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>115</td>\n",
       "      <td>28</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4940.333864</td>\n",
       "      <td>7390310.0</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>5546.22</td>\n",
       "      <td>63999.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6613.670703</td>\n",
       "      <td>12201689.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-03-12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6962.900499</td>\n",
       "      <td>37761446.0</td>\n",
       "      <td>3905.0</td>\n",
       "      <td>6226.05</td>\n",
       "      <td>89950.0</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7120.912973</td>\n",
       "      <td>24318967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>69</td>\n",
       "      <td>2016-03-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2045.355745</td>\n",
       "      <td>4016555.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>5757.79</td>\n",
       "      <td>48500.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6733.317718</td>\n",
       "      <td>3086176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149032</td>\n",
       "      <td>149995</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>399.0</td>\n",
       "      <td>9308.178506</td>\n",
       "      <td>15432706.0</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>5906.85</td>\n",
       "      <td>89000.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7054.100166</td>\n",
       "      <td>8116007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149033</td>\n",
       "      <td>149996</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>83</td>\n",
       "      <td>28</td>\n",
       "      <td>2016-03-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5176.965741</td>\n",
       "      <td>4882439.0</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>5546.22</td>\n",
       "      <td>63999.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6613.670703</td>\n",
       "      <td>12201689.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149034</td>\n",
       "      <td>149997</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>2016-03-28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2984.005274</td>\n",
       "      <td>4433411.0</td>\n",
       "      <td>2108.0</td>\n",
       "      <td>5810.35</td>\n",
       "      <td>72900.0</td>\n",
       "      <td>3199.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7257.073663</td>\n",
       "      <td>12254030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149035</td>\n",
       "      <td>149998</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>78</td>\n",
       "      <td>18</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>300.0</td>\n",
       "      <td>8332.005838</td>\n",
       "      <td>11921249.0</td>\n",
       "      <td>3134.0</td>\n",
       "      <td>6094.26</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7673.683635</td>\n",
       "      <td>19105495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149036</td>\n",
       "      <td>149999</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>213</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5414.296214</td>\n",
       "      <td>1307118.0</td>\n",
       "      <td>3642.0</td>\n",
       "      <td>5210.90</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6536.433015</td>\n",
       "      <td>18983325.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149037 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SaleID  bodyType  brand  brand_type  city   creatDate  fuelType  \\\n",
       "0            0         1      6          44    10  2016-04-04         0   \n",
       "1            1         2      1          10    43  2016-03-09         0   \n",
       "2            2         1     15         115    28  2016-04-02         0   \n",
       "3            3         0     10          75     4  2016-03-12         0   \n",
       "4            4         1      5          36    69  2016-03-13         0   \n",
       "...        ...       ...    ...         ...   ...         ...       ...   \n",
       "149032  149995         4     10          79    45  2016-03-27         0   \n",
       "149033  149996         0     11          83    28  2016-03-12         0   \n",
       "149034  149997         1     11          84    33  2016-03-28         1   \n",
       "149035  149998         3     10          78    18  2016-04-01         1   \n",
       "149036  149999         6     28         213     2  2016-03-05         0   \n",
       "\n",
       "        gearbox  is_train  kilometer  ...  brand_type_min  brand_type_std  \\\n",
       "0           0.0         1       12.5  ...            30.0     2707.072478   \n",
       "1           0.0         1       15.0  ...           100.0     7802.604925   \n",
       "2           0.0         1       12.5  ...           100.0     4940.333864   \n",
       "3           1.0         1       15.0  ...            35.0     6962.900499   \n",
       "4           0.0         1        5.0  ...            50.0     2045.355745   \n",
       "...         ...       ...        ...  ...             ...             ...   \n",
       "149032      1.0         1       15.0  ...           399.0     9308.178506   \n",
       "149033      0.0         1       10.0  ...            80.0     5176.965741   \n",
       "149034      0.0         1        6.0  ...            45.0     2984.005274   \n",
       "149035      0.0         1       15.0  ...           300.0     8332.005838   \n",
       "149036      1.0         1       12.5  ...          1000.0     5414.296214   \n",
       "\n",
       "        brand_type_sum  city_amount  city_average city_max  city_median  \\\n",
       "0            7868239.0       3521.0       6176.86  73900.0       3500.0   \n",
       "1           46879429.0       1472.0       5449.87  42700.0       3200.0   \n",
       "2            7390310.0       2199.0       5546.22  63999.0       3200.0   \n",
       "3           37761446.0       3905.0       6226.05  89950.0       3700.0   \n",
       "4            4016555.0        535.0       5757.79  48500.0       3450.0   \n",
       "...                ...          ...           ...      ...          ...   \n",
       "149032      15432706.0       1373.0       5906.85  89000.0       3500.0   \n",
       "149033       4882439.0       2199.0       5546.22  63999.0       3200.0   \n",
       "149034       4433411.0       2108.0       5810.35  72900.0       3199.5   \n",
       "149035      11921249.0       3134.0       6094.26  99999.0       3450.0   \n",
       "149036       1307118.0       3642.0       5210.90  81000.0       2800.0   \n",
       "\n",
       "        city_min     city_std    city_sum  \n",
       "0           20.0  7397.792986  21754915.0  \n",
       "1           20.0  6140.251744   8027664.0  \n",
       "2           30.0  6613.670703  12201689.0  \n",
       "3           20.0  7120.912973  24318967.0  \n",
       "4           50.0  6733.317718   3086176.0  \n",
       "...          ...          ...         ...  \n",
       "149032      60.0  7054.100166   8116007.0  \n",
       "149033      30.0  6613.670703  12201689.0  \n",
       "149034      15.0  7257.073663  12254030.0  \n",
       "149035      30.0  7673.683635  19105495.0  \n",
       "149036      15.0  6536.433015  18983325.0  \n",
       "\n",
       "[149037 rows x 57 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SaleID', 'creatDate', 'is_train', 'price', 'regDate', 'v_6', 'v_7', 'creatDate_year', 'city_max']\n"
     ]
    }
   ],
   "source": [
    "target = ['price']\n",
    "'''\n",
    "sparse_features = ['A1', 'A2', 'A3', 'B1', 'B2', 'B3', 'C1', 'C2', 'C3', 'D1', 'D2', 'E1',\n",
    "       'E11', 'E12',  'E15', 'E18',  # 'E10','E13', 'E14','E16', 'E17', 'E19', 'E2','E21','E22','E3','E5','E7','E9',\n",
    "       'E20',   'E23', 'E24', 'E25', 'E26', 'E27', 'E28','E16', 'E17', 'E19', 'E2', 'E21', 'E22', 'E3', 'E5', 'E7', 'E9',\n",
    "       'per_day_hour_click_rate', 'per_hour_click_rate', 'AB_click_rate', 'BD1_click_rate', 'BD2_click_rate',\n",
    "       'E29',  'E4',  'E6',  'E8',   'day',\n",
    "        'shijianduan', 'time', 'weekend',]#\n",
    "       #'per_day_hour_click_rate', 'per_day_click_rate', 'per_hour_click_rate']\n",
    "\n",
    "notfeature = [ 'ID','date_index','date','week','before_day_hour_click_rate','after_day_hour_click_rate','week_day_hour_click_rate']\n",
    "'''\n",
    "not_features = [i for i in train_data.columns if i not in feats]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(not_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['power', 'kilometer', 'during_month', 'during_year', 'brand_amount',\\n       'brand_price_average', 'brand_price_max', 'brand_price_median',\\n       'brand_price_min', 'brand_price_std', 'brand_price_sum', 'city',\\n       'brand_type_amount', 'brand_type_average', 'brand_type_max',\\n       'brand_type_median', 'brand_type_min', 'brand_type_std', 'regDate_year',\\n       'brand_type_sum', 'city_amount', 'city_average', 'city_median',\\n       'city_min', 'city_std', 'city_sum', 'v_0', 'v_1', 'v_2', 'v_3', 'v_4',\\n       'v_9', 'v_5', 'v_8', 'v_10', 'v_11', 'v_12', 'v_13', 'v_14'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-f471bc579dc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtrain_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrain_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_feats\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_feats\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_feats\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_feats\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m '''\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3467\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3468\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3469\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3470\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3471\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3494\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3495\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3496\u001b[1;33m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3497\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3498\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"raise_missing\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1092\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1175\u001b[0m                 raise KeyError(\n\u001b[0;32m   1176\u001b[0m                     \"None of [{key}] are in the [{axis}]\".format(\n\u001b[1;32m-> 1177\u001b[1;33m                         \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m                     )\n\u001b[0;32m   1179\u001b[0m                 )\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['power', 'kilometer', 'during_month', 'during_year', 'brand_amount',\\n       'brand_price_average', 'brand_price_max', 'brand_price_median',\\n       'brand_price_min', 'brand_price_std', 'brand_price_sum', 'city',\\n       'brand_type_amount', 'brand_type_average', 'brand_type_max',\\n       'brand_type_median', 'brand_type_min', 'brand_type_std', 'regDate_year',\\n       'brand_type_sum', 'city_amount', 'city_average', 'city_median',\\n       'city_min', 'city_std', 'city_sum', 'v_0', 'v_1', 'v_2', 'v_3', 'v_4',\\n       'v_9', 'v_5', 'v_8', 'v_10', 'v_11', 'v_12', 'v_13', 'v_14'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "train_x = train_data[feats]\n",
    "train_y = train_data['price'].values\n",
    "test = test[feats]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_X = pd.DataFrame()\n",
    "test_X = pd.DataFrame()\n",
    "train_X[num_feats] = scaler.fit_transform(train_x[num_feats])\n",
    "test_X[num_feats] = scaler.transform(test[num_feats])\n",
    "'''\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "for feat in num_feats:\n",
    "    print(\"Process: \", feat)\n",
    "    data[feat] = mms.fit_transform(np.array(data[feat]).reshape(-1, 1))\n",
    "print(\"Process dense finish \")\n",
    "'''\n",
    "# 2.count #unique features for each sparse field,and record dense feature field name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=2, shuffle=True, random_state=1996)\n",
    "NN_predictions = np.zeros((test_X.shape[0], 1))\n",
    "oof_preds = np.zeros((train_X.shape[0], 1))\n",
    "\n",
    "patience = 100   ## How many steps to stop\n",
    "call_ES = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=patience, verbose=100,\n",
    "                                        mode='auto', baseline=None)\n",
    "\n",
    "for fold_, (trn_, val_) in enumerate(folds.split(train_x)):\n",
    "    print(\"fold {}\".format(fold_ + 1))\n",
    "    x_train, y_train = train_X[trn_], train_y[trn_]\n",
    "    x_valid, y_valid = train_X[val_], train_y[val_]\n",
    "\n",
    "\n",
    "    model = MLP(dropout_rate=0.5, activation='relu')\n",
    "    model.compile( Adam(lr=0.1, decay=0),loss='mse')#, metrics=['mse'],optimizer='adam',\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        validation_data=[x_valid, y_valid],\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[call_ES, ],\n",
    "                        shuffle=True,\n",
    "                        verbose=1)\n",
    "\n",
    "    # plot_loss_acc(history, fold_ + 1)\n",
    "\n",
    "    print('Loading Best Model')\n",
    "    # # Get predicted probabilities for each class\n",
    "    oof_preds[val_] = model.predict(x_valid, batch_size=batch_size)\n",
    "    NN_predictions += model.predict(test_X, batch_size=batch_size) / folds.n_splits\n",
    "\n",
    "print(NN_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "Train on 13200 samples, validate on 13200 samples\n",
      "Epoch 1/100\n",
      "13200/13200 [==============================] - 36s 3ms/step - loss: 668381.7466 - val_loss: 12063936.0339\n",
      "Epoch 2/100\n",
      "13200/13200 [==============================] - 4s 319us/step - loss: 368842.0299 - val_loss: 10874914.8445\n",
      "Epoch 3/100\n",
      "13200/13200 [==============================] - 5s 348us/step - loss: 345013.1106 - val_loss: 3612330.7148\n",
      "Epoch 4/100\n",
      "13200/13200 [==============================] - 13s 980us/step - loss: 327318.3086 - val_loss: 1874428.3529\n",
      "Epoch 5/100\n",
      "13200/13200 [==============================] - 4s 294us/step - loss: 316248.0072 - val_loss: 1571645.2358\n",
      "Epoch 6/100\n",
      "13200/13200 [==============================] - 3s 235us/step - loss: 315844.6537 - val_loss: 1492176.2415\n",
      "Epoch 7/100\n",
      "13200/13200 [==============================] - 3s 226us/step - loss: 315287.5698 - val_loss: 980435.9378\n",
      "Epoch 8/100\n",
      "13200/13200 [==============================] - 3s 216us/step - loss: 311399.2918 - val_loss: 892793.7068\n",
      "Epoch 9/100\n",
      "13200/13200 [==============================] - 3s 220us/step - loss: 302026.6437 - val_loss: 848306.7339\n",
      "Epoch 10/100\n",
      "13200/13200 [==============================] - 3s 225us/step - loss: 308187.4238 - val_loss: 707055.1447\n",
      "Epoch 11/100\n",
      "13200/13200 [==============================] - 3s 247us/step - loss: 297823.7877 - val_loss: 535316.6068\n",
      "Epoch 12/100\n",
      "13200/13200 [==============================] - 3s 247us/step - loss: 291470.8379 - val_loss: 679594.5030\n",
      "Epoch 13/100\n",
      "13200/13200 [==============================] - 3s 253us/step - loss: 284710.4750 - val_loss: 594953.8830\n",
      "Epoch 14/100\n",
      "13200/13200 [==============================] - 3s 242us/step - loss: 285501.6327 - val_loss: 496309.7098\n",
      "Epoch 15/100\n",
      "13200/13200 [==============================] - 3s 245us/step - loss: 295289.7784 - val_loss: 509614.9123\n",
      "Epoch 16/100\n",
      "13200/13200 [==============================] - 3s 229us/step - loss: 283926.1009 - val_loss: 472316.7964\n",
      "Epoch 17/100\n",
      "13200/13200 [==============================] - 3s 247us/step - loss: 285228.5553 - val_loss: 433637.2829\n",
      "Epoch 18/100\n",
      "13200/13200 [==============================] - 3s 225us/step - loss: 282393.6439 - val_loss: 418637.5318\n",
      "Epoch 19/100\n",
      "13200/13200 [==============================] - 3s 224us/step - loss: 275667.3314 - val_loss: 366924.0000\n",
      "Epoch 20/100\n",
      "13200/13200 [==============================] - 3s 225us/step - loss: 274347.3455 - val_loss: 389858.6641\n",
      "Epoch 21/100\n",
      "13200/13200 [==============================] - 3s 238us/step - loss: 278902.3099 - val_loss: 340111.4359\n",
      "Epoch 22/100\n",
      "13200/13200 [==============================] - 3s 232us/step - loss: 269727.6420 - val_loss: 397628.7489\n",
      "Epoch 23/100\n",
      "13200/13200 [==============================] - 3s 226us/step - loss: 288431.8332 - val_loss: 341083.5610\n",
      "Epoch 24/100\n",
      "13200/13200 [==============================] - 3s 241us/step - loss: 280158.5160 - val_loss: 335991.3253\n",
      "Epoch 25/100\n",
      "13200/13200 [==============================] - 3s 227us/step - loss: 271921.5506 - val_loss: 333761.4296\n",
      "Epoch 26/100\n",
      "13200/13200 [==============================] - 3s 236us/step - loss: 267605.9951 - val_loss: 297837.6642\n",
      "Epoch 27/100\n",
      "13200/13200 [==============================] - 3s 261us/step - loss: 286437.9902 - val_loss: 327104.5001\n",
      "Epoch 28/100\n",
      "13200/13200 [==============================] - 3s 246us/step - loss: 279053.1805 - val_loss: 394744.0813\n",
      "Epoch 29/100\n",
      "13200/13200 [==============================] - 3s 254us/step - loss: 268408.5074 - val_loss: 341628.6507\n",
      "Epoch 30/100\n",
      "13200/13200 [==============================] - 4s 322us/step - loss: 248669.5234 - val_loss: 321519.2272\n",
      "Epoch 31/100\n",
      "13200/13200 [==============================] - 4s 312us/step - loss: 265968.7864 - val_loss: 327144.0487\n",
      "Epoch 32/100\n",
      "13200/13200 [==============================] - 4s 300us/step - loss: 260943.7862 - val_loss: 278150.2211\n",
      "Epoch 33/100\n",
      "13200/13200 [==============================] - 4s 291us/step - loss: 258188.9321 - val_loss: 286227.0176\n",
      "Epoch 34/100\n",
      "13200/13200 [==============================] - 4s 304us/step - loss: 265653.5504 - val_loss: 280706.1187\n",
      "Epoch 35/100\n",
      "13200/13200 [==============================] - 4s 335us/step - loss: 258818.2584 - val_loss: 274348.3430\n",
      "Epoch 36/100\n",
      "13200/13200 [==============================] - 4s 304us/step - loss: 258176.7063 - val_loss: 276634.4656\n",
      "Epoch 37/100\n",
      "13200/13200 [==============================] - 9s 689us/step - loss: 260121.0767 - val_loss: 297988.7264\n",
      "Epoch 38/100\n",
      "13200/13200 [==============================] - 9s 674us/step - loss: 262732.1469 - val_loss: 254162.0402\n",
      "Epoch 39/100\n",
      "13200/13200 [==============================] - 4s 291us/step - loss: 261494.3309 - val_loss: 233319.5566\n",
      "Epoch 40/100\n",
      "13200/13200 [==============================] - 4s 321us/step - loss: 260244.8478 - val_loss: 259570.3947\n",
      "Epoch 41/100\n",
      "13200/13200 [==============================] - 8s 618us/step - loss: 236258.1212 - val_loss: 241020.8774\n",
      "Epoch 42/100\n",
      "13200/13200 [==============================] - 4s 308us/step - loss: 251097.5098 - val_loss: 241721.2493\n",
      "Epoch 43/100\n",
      "13200/13200 [==============================] - 5s 345us/step - loss: 235613.5465 - val_loss: 243490.7224\n",
      "Epoch 44/100\n",
      "13200/13200 [==============================] - 4s 335us/step - loss: 239075.0771 - val_loss: 255490.5694\n",
      "Epoch 45/100\n",
      "13200/13200 [==============================] - 4s 312us/step - loss: 251555.3084 - val_loss: 233754.2157\n",
      "Epoch 46/100\n",
      "13200/13200 [==============================] - 4s 304us/step - loss: 244015.2795 - val_loss: 240070.4705\n",
      "Epoch 47/100\n",
      "13200/13200 [==============================] - 4s 328us/step - loss: 248198.5308 - val_loss: 231212.5115\n",
      "Epoch 48/100\n",
      "13200/13200 [==============================] - 10s 740us/step - loss: 247542.3894 - val_loss: 220781.5021\n",
      "Epoch 49/100\n",
      "13200/13200 [==============================] - 9s 704us/step - loss: 247319.2007 - val_loss: 250674.4014\n",
      "Epoch 50/100\n",
      "13200/13200 [==============================] - 4s 284us/step - loss: 254597.9176 - val_loss: 232787.2175\n",
      "Epoch 51/100\n",
      "13200/13200 [==============================] - 9s 644us/step - loss: 248231.1584 - val_loss: 286893.9877\n",
      "Epoch 52/100\n",
      "13200/13200 [==============================] - 3s 241us/step - loss: 249713.8808 - val_loss: 223186.4013\n",
      "Epoch 53/100\n",
      "13200/13200 [==============================] - 3s 232us/step - loss: 241602.7320 - val_loss: 257777.1708\n",
      "Epoch 54/100\n",
      "13200/13200 [==============================] - 3s 258us/step - loss: 237034.9335 - val_loss: 216884.5463\n",
      "Epoch 55/100\n",
      "13200/13200 [==============================] - 3s 253us/step - loss: 235039.9193 - val_loss: 225984.6891\n",
      "Epoch 56/100\n",
      "13200/13200 [==============================] - 3s 238us/step - loss: 241197.7320 - val_loss: 214871.5995\n",
      "Epoch 57/100\n",
      "13200/13200 [==============================] - 3s 245us/step - loss: 230196.9865 - val_loss: 218785.0525\n",
      "Epoch 58/100\n",
      "13200/13200 [==============================] - 3s 221us/step - loss: 232817.1604 - val_loss: 232548.1486\n",
      "Epoch 59/100\n",
      "13200/13200 [==============================] - 3s 229us/step - loss: 232575.5905 - val_loss: 224257.6514\n",
      "Epoch 60/100\n",
      "13200/13200 [==============================] - 3s 235us/step - loss: 237460.1206 - val_loss: 223260.4493\n",
      "Epoch 61/100\n",
      "13200/13200 [==============================] - 3s 249us/step - loss: 239061.6366 - val_loss: 233419.7462\n",
      "Epoch 62/100\n",
      "13200/13200 [==============================] - 3s 245us/step - loss: 228767.1697 - val_loss: 299780.8630\n",
      "Epoch 63/100\n",
      "13200/13200 [==============================] - 3s 239us/step - loss: 262098.5721 - val_loss: 285546.1020\n",
      "Epoch 64/100\n",
      "13200/13200 [==============================] - 3s 246us/step - loss: 240670.4420 - val_loss: 252426.0134\n",
      "Epoch 65/100\n",
      "13200/13200 [==============================] - 3s 233us/step - loss: 244623.3829 - val_loss: 240530.2033\n",
      "Epoch 66/100\n",
      "13200/13200 [==============================] - 3s 235us/step - loss: 246140.3684 - val_loss: 219685.1613\n",
      "Epoch 67/100\n",
      "13200/13200 [==============================] - 3s 239us/step - loss: 231789.4708 - val_loss: 231680.3538\n",
      "Epoch 68/100\n",
      "13200/13200 [==============================] - 3s 224us/step - loss: 224085.3831 - val_loss: 228264.5929\n",
      "Epoch 69/100\n",
      "13200/13200 [==============================] - 3s 236us/step - loss: 230230.6666 - val_loss: 231280.1838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "13200/13200 [==============================] - 3s 240us/step - loss: 235101.6600 - val_loss: 214638.9129\n",
      "Epoch 71/100\n",
      "13200/13200 [==============================] - 3s 237us/step - loss: 222319.6428 - val_loss: 240634.0804\n",
      "Epoch 72/100\n",
      "13200/13200 [==============================] - 3s 241us/step - loss: 234314.8885 - val_loss: 214832.8619\n",
      "Epoch 73/100\n",
      "13200/13200 [==============================] - 3s 227us/step - loss: 226345.9753 - val_loss: 261531.2490\n",
      "Epoch 74/100\n",
      "13200/13200 [==============================] - 4s 270us/step - loss: 274993.4141 - val_loss: 290747.0931\n",
      "Epoch 75/100\n",
      "13200/13200 [==============================] - 3s 241us/step - loss: 277937.8244 - val_loss: 257028.7673\n",
      "Epoch 76/100\n",
      "13200/13200 [==============================] - 3s 247us/step - loss: 271076.6811 - val_loss: 242807.6129\n",
      "Epoch 77/100\n",
      "13200/13200 [==============================] - 3s 248us/step - loss: 258422.9538 - val_loss: 225874.3178\n",
      "Epoch 78/100\n",
      "13200/13200 [==============================] - 3s 250us/step - loss: 251562.0435 - val_loss: 233032.9007\n",
      "Epoch 79/100\n",
      "13200/13200 [==============================] - 3s 233us/step - loss: 259759.5391 - val_loss: 221700.0778\n",
      "Epoch 80/100\n",
      "13200/13200 [==============================] - 4s 305us/step - loss: 253406.3782 - val_loss: 219429.2380\n",
      "Epoch 81/100\n",
      "13200/13200 [==============================] - 4s 290us/step - loss: 254444.8245 - val_loss: 225388.6048\n",
      "Epoch 82/100\n",
      "13200/13200 [==============================] - 4s 297us/step - loss: 242581.2172 - val_loss: 224376.0966\n",
      "Epoch 83/100\n",
      "13200/13200 [==============================] - 4s 322us/step - loss: 228244.5345 - val_loss: 222103.7332\n",
      "Epoch 84/100\n",
      "13200/13200 [==============================] - 4s 300us/step - loss: 229784.2190 - val_loss: 209403.6579\n",
      "Epoch 85/100\n",
      "13200/13200 [==============================] - 4s 319us/step - loss: 257010.3912 - val_loss: 224861.9043\n",
      "Epoch 86/100\n",
      "13200/13200 [==============================] - 4s 296us/step - loss: 231177.9769 - val_loss: 235445.6025\n",
      "Epoch 87/100\n",
      "13200/13200 [==============================] - 4s 306us/step - loss: 232288.8418 - val_loss: 281214.0150\n",
      "Epoch 88/100\n",
      "13200/13200 [==============================] - 4s 304us/step - loss: 278769.5884 - val_loss: 247666.0067\n",
      "Epoch 89/100\n",
      "13200/13200 [==============================] - 4s 306us/step - loss: 261476.8851 - val_loss: 244339.8789\n",
      "Epoch 90/100\n",
      "13200/13200 [==============================] - 4s 302us/step - loss: 265773.5955 - val_loss: 232620.0966\n",
      "Epoch 91/100\n",
      "13200/13200 [==============================] - 5s 346us/step - loss: 261288.9822 - val_loss: 248053.4626\n",
      "Epoch 92/100\n",
      "13200/13200 [==============================] - 12s 911us/step - loss: 264377.9340 - val_loss: 249204.8554\n",
      "Epoch 93/100\n",
      "13200/13200 [==============================] - 3s 256us/step - loss: 254684.8425 - val_loss: 226402.3907\n",
      "Epoch 94/100\n",
      "13200/13200 [==============================] - 4s 287us/step - loss: 254686.3928 - val_loss: 222573.5707\n",
      "Epoch 95/100\n",
      "13200/13200 [==============================] - 12s 899us/step - loss: 254151.6614 - val_loss: 232930.1883\n",
      "Epoch 96/100\n",
      "13200/13200 [==============================] - 3s 264us/step - loss: 240533.8085 - val_loss: 218873.3536\n",
      "Epoch 97/100\n",
      "13200/13200 [==============================] - 4s 306us/step - loss: 243688.3705 - val_loss: 222299.6063\n",
      "Epoch 98/100\n",
      "13200/13200 [==============================] - 4s 277us/step - loss: 236254.7052 - val_loss: 205476.6748\n",
      "Epoch 99/100\n",
      "13200/13200 [==============================] - 12s 890us/step - loss: 248289.7335 - val_loss: 210462.6349\n",
      "Epoch 100/100\n",
      "13200/13200 [==============================] - 5s 357us/step - loss: 243247.4584 - val_loss: 208523.8900\n",
      "Loading Best Model\n",
      "fold 2\n",
      "Train on 13200 samples, validate on 13200 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-a2d755c1e57d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcall_ES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         verbose=1)\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;31m# plot_loss_acc(history, fold_ + 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2658\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_make_callable_from_options'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2659\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    195\u001b[0m                 \u001b[1;31m# not already marked as initialized.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m                 is_initialized = session.run(\n\u001b[1;32m--> 197\u001b[1;33m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[0;32m    198\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1261\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m   1263\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1295\u001b[1;33m       \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m   \u001b[1;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv(\"nn_data1010.csv\")\n",
    "\n",
    "# del data['forecastVolum'],data['pred_label']\n",
    "# train_data = data[data['mt']<25]\n",
    "# test = data[data['mt']>=25]\n",
    "# train_data.head()\n",
    "\n",
    "\n",
    "## load data\n",
    "# train_data = pd.read_csv('data/train.csv')\n",
    "# test_data = pd.read_csv('data/test.csv')\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "classes = 1\n",
    "\n",
    "## category feature one_hot\n",
    "test_data['price'] = -1\n",
    "\n",
    "\n",
    "num_feats = ['power', 'kilometer', 'during_month',  'during_year','brand_amount',\n",
    "       'brand_price_average', 'brand_price_max', 'brand_price_median',\n",
    "       'brand_price_min', 'brand_price_std', 'brand_price_sum','city',\n",
    "       'brand_type_amount', 'brand_type_average', 'brand_type_max',\n",
    "       'brand_type_median', 'brand_type_min', 'brand_type_std','regDate_year', \n",
    "       'brand_type_sum',\n",
    "       'city_amount',\n",
    "       'city_average','city_median', 'city_min', 'city_std',\n",
    "       'city_sum',\n",
    "       'v_0', 'v_1', 'v_2', 'v_3', 'v_4', 'v_9','v_5',\n",
    "       'v_8',  'v_10', 'v_11', 'v_12', 'v_13','v_14' ] # 'v_6', 'v_7','v_9', 'v_5','v_6','v_11', 'city_max', \n",
    "\n",
    "cate_feats = ['name', 'model', 'brand', 'bodyType', 'fuelType', 'gearbox',\n",
    "             'notRepairedDamage', 'regionCode','brand_type']\n",
    "\n",
    "feats = cate_feats+num_feats\n",
    "\n",
    "for item in cate_feats:\n",
    "    data[item] = LabelEncoder().fit_transform(data[item])\n",
    "    item_dummies = pd.get_dummies(data[item])\n",
    "    item_dummies.columns = [item + str(i + 1) for i in range(item_dummies.shape[1])]\n",
    "    data = pd.concat([data, item_dummies], axis=1)\n",
    "data.drop(cate_feature,axis=1,inplace=True)\n",
    "\n",
    "train = data[data['price'] != -1]\n",
    "test = data[data['price'] == -1]\n",
    "\n",
    "##Clean up the memory\n",
    "# del data, train_data, test_data\n",
    "# gc.collect()\n",
    "\n",
    "## get train feature\n",
    "# del_feature = [ \n",
    "#  'id',\n",
    "#  'model_adcode',]\n",
    "# features = [i for i in train.columns if i not in del_feature]\n",
    "\n",
    "\n",
    "train_x = train[features]\n",
    "train_y = train['label'].values\n",
    "test = test[features]\n",
    "\n",
    "## Fill missing value\n",
    "# for i in train_x.columns:\n",
    "#     # print(i, train_x[i].isnull().sum(), test[i].isnull().sum())\n",
    "#     if train_x[i].isnull().sum() != 0:\n",
    "#         train_x[i].fillna(0, inplace=True)\n",
    "#         test[i].fillna(0, inplace=True)\n",
    "\n",
    "## normalized\n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(train_x)\n",
    "test_X = scaler.transform(test)\n",
    "# train_X  = train_x.copy()\n",
    "# test_X   = test.copy()\n",
    "\n",
    "\n",
    "# K.clear_session()\n",
    "\n",
    "\n",
    "\n",
    "folds = KFold(n_splits=2, shuffle=True, random_state=1996)\n",
    "NN_predictions = np.zeros((test_X.shape[0], 1))\n",
    "oof_preds = np.zeros((train_X.shape[0], 1))\n",
    "\n",
    "patience = 100   ## How many steps to stop\n",
    "call_ES = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=patience, verbose=100,\n",
    "                                        mode='auto', baseline=None)\n",
    "\n",
    "for fold_, (trn_, val_) in enumerate(folds.split(train_x)):\n",
    "    print(\"fold {}\".format(fold_ + 1))\n",
    "    x_train, y_train = train_X[trn_], train_y[trn_]\n",
    "    x_valid, y_valid = train_X[val_], train_y[val_]\n",
    "\n",
    "\n",
    "    model = MLP(dropout_rate=0.5, activation='relu')\n",
    "    model.compile( Adam(lr=0.1, decay=0),loss='mse')#, metrics=['mse'],optimizer='adam',\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        validation_data=[x_valid, y_valid],\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[call_ES, ],\n",
    "                        shuffle=True,\n",
    "                        verbose=1)\n",
    "\n",
    "    # plot_loss_acc(history, fold_ + 1)\n",
    "\n",
    "    print('Loading Best Model')\n",
    "    # # Get predicted probabilities for each class\n",
    "    oof_preds[val_] = model.predict(x_valid, batch_size=batch_size)\n",
    "    NN_predictions += model.predict(test_X, batch_size=batch_size) / folds.n_splits\n",
    "\n",
    "print(NN_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(dropout_rate=0.5, activation='relu'):\n",
    "    start_neurons = 600\n",
    "    model = Sequential()\n",
    "    model.add(Dense(start_neurons, input_dim=train_X.shape[1], activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(start_neurons , activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(start_neurons, activation=activation))#// 2\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(start_neurons// 2, activation=activation))#// 2\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "\n",
    "    \n",
    "    model.add(Dense(start_neurons// 4 , activation=activation))#// 4\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "\n",
    "    model.add(Dense(start_neurons // 8, activation=activation))#// 8\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "\n",
    "\n",
    "    model.add(Dense(classes, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss: 230082.7578 - val_loss: 191146.1819\n",
    "Loading Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[155.35545349],\n",
       "       [192.12611389],\n",
       "       [168.08506012],\n",
       "       [260.80189514],\n",
       "       [622.19866943],\n",
       "       [173.06531525],\n",
       "       [269.92922974],\n",
       "       [165.67009735],\n",
       "       [957.44317627],\n",
       "       [177.01425171]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_predictions[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
