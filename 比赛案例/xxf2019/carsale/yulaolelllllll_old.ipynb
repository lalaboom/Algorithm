{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-2-027fb5b461bb>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-027fb5b461bb>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    特征：\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "特征：\n",
    "   'label','popularity','carCommentVolum','newsReplyVolum'平移了12个月\n",
    "    train:\n",
    "        1,  2,  3,  4,  5,  6,  7,  8,  9,  10,  11,  12\n",
    "        13, 14, 15, 16, 17, 18, 19, 20, 21, 22,  23,  24 \n",
    "        \n",
    "    test: 21,22,23,24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import os \n",
    "# import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adcode</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>forecastVolum</th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>province</th>\n",
       "      <th>regMonth</th>\n",
       "      <th>regYear</th>\n",
       "      <th>salesVolume</th>\n",
       "      <th>popularity</th>\n",
       "      <th>carCommentVolum</th>\n",
       "      <th>newsReplyVolum</th>\n",
       "      <th>label</th>\n",
       "      <th>mt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>36955</td>\n",
       "      <td>350000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5364</td>\n",
       "      <td>59</td>\n",
       "      <td>福建</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36956</td>\n",
       "      <td>210000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5365</td>\n",
       "      <td>59</td>\n",
       "      <td>辽宁</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36957</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5366</td>\n",
       "      <td>59</td>\n",
       "      <td>重庆</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36958</td>\n",
       "      <td>610000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5367</td>\n",
       "      <td>59</td>\n",
       "      <td>陕西</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36959</td>\n",
       "      <td>230000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5368</td>\n",
       "      <td>59</td>\n",
       "      <td>黑龙江</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       adcode  bodyType  forecastVolum    id  model province  regMonth  \\\n",
       "36955  350000         0            NaN  5364     59       福建         4   \n",
       "36956  210000         0            NaN  5365     59       辽宁         4   \n",
       "36957  500000         0            NaN  5366     59       重庆         4   \n",
       "36958  610000         0            NaN  5367     59       陕西         4   \n",
       "36959  230000         0            NaN  5368     59      黑龙江         4   \n",
       "\n",
       "       regYear  salesVolume  popularity  carCommentVolum  newsReplyVolum  \\\n",
       "36955     2018          NaN         NaN              NaN             NaN   \n",
       "36956     2018          NaN         NaN              NaN             NaN   \n",
       "36957     2018          NaN         NaN              NaN             NaN   \n",
       "36958     2018          NaN         NaN              NaN             NaN   \n",
       "36959     2018          NaN         NaN              NaN             NaN   \n",
       "\n",
       "       label  mt  \n",
       "36955    NaN  28  \n",
       "36956    NaN  28  \n",
       "36957    NaN  28  \n",
       "36958    NaN  28  \n",
       "36959    NaN  28  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path  = './ccf_car/'\n",
    "train_sales  = pd.read_csv('train_sales_data.csv')\n",
    "\n",
    "\n",
    "train_search = pd.read_csv('train_search_data.csv')\n",
    "train_user   = pd.read_csv('train_user_reply_data.csv')\n",
    "evaluation_public = pd.read_csv('evaluation_public.csv')\n",
    "# submit_example    = pd.read_csv('submit_example.csv')\n",
    "data = pd.concat([train_sales, evaluation_public], ignore_index=True)\n",
    "data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth'])\n",
    "data['label'] = data['salesVolume']\n",
    "data['id'] = data['id'].fillna(0).astype(int)\n",
    "data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "#索引-->value\n",
    "#LabelEncoder\n",
    "for i in ['bodyType', 'model']:\n",
    "    data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "    #key-->value\n",
    "data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']\n",
    "initial_key_list = ['adcode','bodyType','forecastVolum','id','model','province','regMonth','regYear','salesVolume','popularity','carCommentVolum','newsReplyVolum'\t,'label','mt']\n",
    "data = data[initial_key_list].copy()\n",
    "\n",
    "\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windows_feature(data,judge):\n",
    "    if (judge >1):\n",
    "        print(\"windows_var_features start\")\n",
    "        del data['windows4_var'],data['windows5_var'],data['windows12_var'],data['model_adcode']\n",
    "#         del data['ratio'],data['differ'],data['ratio2'],data['differ2']\n",
    "        df = data.copy()\n",
    "        df_all = pd.DataFrame()\n",
    "        df['model_adcode'] = df['adcode'] + df['model']\n",
    "        model_adcode = list(df.model_adcode.unique())\n",
    "        for i in tqdm(model_adcode):\n",
    "            idx = (df['model_adcode']==i)\n",
    "            df2 = df[idx] \n",
    "#             df2['windows3_var'] = df2['label'].rolling(3).var()\n",
    "            df2['windows4_var'] = df2['label'].rolling(4).var()\n",
    "            df2['windows5_var'] = df2['label'].rolling(5).var()\n",
    "          \n",
    "            df2['windows12_var'] = df2['label'].rolling(12).var()\n",
    "            \n",
    "#             df2['windows3_std'] = df2['label'].rolling(3).std()\n",
    "#             df2['windows4_std'] = df2['label'].rolling(2).mean()\n",
    "#             df2['windows5_std'] = df2['label'].rolling(3).mean()\n",
    "           \n",
    "#             df2['windows12_std'] = df2['label'].rolling(4).mean()\n",
    "            \n",
    "#             df2['ratio'] = df2.groupby('model_adcode')['label'].apply(lambda x: x / x.shift(1)) #.apply(lambda x: x - x.shift(1)).reset_index()\n",
    "#             df2['differ'] = df2.groupby('model_adcode')['label'].apply(lambda x: x - x.shift(1))\n",
    "            \n",
    "#             df2['ratio2'] = df2.groupby('model_adcode')['ratio'].apply(lambda x: x / x.shift(1)) #.apply(lambda x: x - x.shift(1)).reset_index()\n",
    "#             df2['differ2'] = df2.groupby('model_adcode')['differ'].apply(lambda x: x - x.shift(1))\n",
    "            \n",
    "            df_all = pd.concat([df_all, df2], ignore_index=True)\n",
    "        data = data.merge(df_all, 'left', on=['adcode','bodyType','forecastVolum','id','model','province','regMonth','regYear','salesVolume','popularity','carCommentVolum','newsReplyVolum','pred_label','label','mt'])\n",
    "        print(\"windows_var_features end\")\n",
    "        return data\n",
    "    else:\n",
    "        print(\"windows_var_features start\")\n",
    "        df = data.copy()\n",
    "        df_all = pd.DataFrame()\n",
    "        df['model_adcode'] = df['adcode'] + df['model']\n",
    "        model_adcode = list(df.model_adcode.unique())\n",
    "        for i in tqdm(model_adcode):\n",
    "            idx = (df['model_adcode']==i)\n",
    "            df2 = df[idx]\n",
    "            \n",
    "#             df2['windows3_var'] = df2['label'].rolling(3).var()\n",
    "            df2['windows4_var'] = df2['label'].rolling(4).var()\n",
    "            df2['windows5_var'] = df2['label'].rolling(6).var()\n",
    "            \n",
    "            df2['windows12_var'] = df2['label'].rolling(12).var()\n",
    "            \n",
    "#             df2['windows3_std'] = df2['label'].rolling(3).std()\n",
    "#             df2['windows4_std'] = df2['label'].rolling(2).mean()\n",
    "#             df2['windows5_std'] = df2['label'].rolling(3).mean()\n",
    "           \n",
    "#             df2['windows12_std'] = df2['label'].rolling(4).mean()\n",
    "            \n",
    "#             df2['ratio'] = df2.groupby('model_adcode')['label'].apply(lambda x: x / x.shift(1)) #.apply(lambda x: x - x.shift(1)).reset_index()\n",
    "#             df2['differ'] = df2.groupby('model_adcode')['label'].apply(lambda x: x - x.shift(1))\n",
    "#             df2['ratio2'] = df2.groupby('model_adcode')['ratio'].apply(lambda x: x / x.shift(1)) #.apply(lambda x: x - x.shift(1)).reset_index()\n",
    "#             df2['differ2'] = df2.groupby('model_adcode')['differ'].apply(lambda x: x - x.shift(1))\n",
    "\n",
    "            df_all = pd.concat([df_all, df2], ignore_index=True)\n",
    "        data = data.merge(df_all, 'left', on=['adcode','bodyType','forecastVolum','id','model','province','regMonth','regYear','salesVolume','popularity','carCommentVolum','newsReplyVolum','label','mt'])\n",
    "        print(\"windows_var_features end\")\n",
    "        return data\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat_feature(df_):   \n",
    "    df = df_.copy()\n",
    "    stat_feat = []\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "    for col in tqdm(['label','popularity']):#,'newsReplyVolum'\n",
    "        # shift\n",
    "        for i in [1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])\n",
    "        for i in [1,2,3,4]:\n",
    "            df[\"differ_{}_{}\".format(col,i)] = df['{}'.format(col)] -df['shift_model_adcode_mt_{}_{}'.format(col,i)]\n",
    "#             stat_feat.append(\"differ_{}_{}\".format(col,i))\n",
    "        df[\"differ2_{}_{}\".format(col,1)] = df[\"differ_{}_{}\".format(col,2)] - df[\"differ_{}_{}\".format(col,1)]\n",
    "        stat_feat.append(\"differ2_{}_{}\".format(col,1))\n",
    "        df[\"differ2_{}_{}\".format(col,2)] = df[\"differ_{}_{}\".format(col,3)] - df[\"differ_{}_{}\".format(col,2)]\n",
    "        stat_feat.append(\"differ2_{}_{}\".format(col,2))\n",
    "        df[\"differ2_{}_{}\".format(col,3)] = df[\"differ_{}_{}\".format(col,4)] - df[\"differ_{}_{}\".format(col,3)]\n",
    "        stat_feat.append(\"differ2_{}_{}\".format(col,3))\n",
    "    return df,stat_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_score(data, pred='pred_label', label='true_sales', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    y = pd.read_csv(\"valid_data_y.csv\")\n",
    "    data = data.merge(y, 'left', on=['id'])\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb'):   \n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**4-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.01, min_child_samples=1, random_state=1024,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,\n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "                  \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              categorical_feature=cate_feat, \n",
    "              early_stopping_rounds=100, verbose=100)      \n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.01, n_estimators=4000, \n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9, \n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse' \n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              early_stopping_rounds=100, verbose=100)   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_model(df_, m, m_type):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分\n",
    "    st = 9\n",
    "    all_idx   = (df['mt'].between(st , m-1))\n",
    "    train_idx = (df['mt'].between(st , m-5))\n",
    "    valid_idx = (df['mt'].between(m-4, m-4))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    \n",
    "    print('all_idx  :',st ,m-1)\n",
    "    print('train_idx:',st ,m-5)\n",
    "    print('valid_idx:',m-4,m-4)\n",
    "    print('test_idx :',m  ,m  )  \n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['label']   \n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type)  \n",
    "    # offline\n",
    "    df['pred_label'] = model.predict(df[features])\n",
    "    best_score = valid_score(df[valid_idx]) \n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'], categorical_feature=cate_feat)\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'])\n",
    "    df['forecastVolum'] = model.predict(df[features])\n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    print(sub.shape)\n",
    "    return sub,df[valid_idx]['pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows_var_features start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1320/1320 [00:16<00:00, 80.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows_var_features end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 38\n",
      "all_idx  : 9 24\n",
      "train_idx: 9 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['windows4_var', 'windows12_var', 'windows5_var'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ac9ac9b2eff3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_feat\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcate_feat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0msub\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;31m#     online_test_idx  = (data_df['mt'].between(21  , 24  ))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"---\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-7e7159aae985>\u001b[0m in \u001b[0;36mget_train_model\u001b[1;34m(df_, m, m_type)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_idx :'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m  \u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m  \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# 最终确认\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mtrain_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mtrain_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mvalid_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2984\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2986\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"raise_missing\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1092\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"loc\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not in index\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['windows4_var', 'windows12_var', 'windows5_var'] not in index\""
     ]
    }
   ],
   "source": [
    "for month in [25,26,27,28]: \n",
    "    judge = month-24\n",
    "    m_type = 'lgb' \n",
    "    data = windows_feature(data,judge)\n",
    "#     data = windowsPop_feature(data,judge)\n",
    "    data_df, stat_feat = get_stat_feature(data)\n",
    "    \n",
    "    win_feat = ['windows4_var','windows5_var','windows12_var']\n",
    "#     winPop_feat = ['windowsPop4_var','windowsPop4_std','windowsPop5_var','windowsPop5_std','windowsPop12_var','windowsPop12_std']\n",
    "#     ,'windows6_var','windows6_std']\n",
    "#     qushi_feat = ['ratio2','differ2']\n",
    "    num_feat = ['regYear','regMonth'] + stat_feat +win_feat#,'windows_var','windows_std'\n",
    "    cate_feat = ['adcode','bodyType','model']\n",
    "\n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "\n",
    "    features = num_feat + cate_feat\n",
    "    print(len(features), len(set(features)))\n",
    "    sub,val_pred = get_train_model(data_df, month, m_type)\n",
    "#     online_test_idx  = (data_df['mt'].between(21  , 24  ))\n",
    "    print(\"---\")\n",
    "    print(data.loc[(data.regMonth==month)].shape)\n",
    "    data.loc[(data.mt==month), 'salesVolume'   ] = sub['forecastVolum'].values\n",
    "    data.loc[(data.mt==(month)), 'label'      ] = sub['forecastVolum'].values\n",
    "    data.loc[(data.mt==(month)), 'pred_label'      ] = sub['forecastVolum'].values\n",
    "#     data['n_label'] = data['label'] / data['model_weight']\n",
    "\n",
    "\n",
    "\n",
    "    # # sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "# # sub.columns = ['id','forecastVolum']\n",
    "# # sub[['id','forecastVolum']].round().astype(int).to_csv('submit/yulao_lgb.csv', index=False)\n",
    "# best_score = online_score(data[online_test_idx]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>forecastVolum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>31680</td>\n",
       "      <td>1</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31681</td>\n",
       "      <td>2</td>\n",
       "      <td>309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31682</td>\n",
       "      <td>3</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31683</td>\n",
       "      <td>4</td>\n",
       "      <td>274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31684</td>\n",
       "      <td>5</td>\n",
       "      <td>351.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  forecastVolum\n",
       "31680   1          269.0\n",
       "31681   2          309.0\n",
       "31682   3          153.0\n",
       "31683   4          274.0\n",
       "31684   5          351.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub.columns = ['id','forecastVolum']\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[['id','forecastVolum']].round().astype(int).to_csv('submit/lgb0922.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows_var_features start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1320/1320 [00:25<00:00, 52.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows_var_features end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 28.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 37\n",
      "all_idx  : 5 20\n",
      "train_idx: 5 16\n",
      "valid_idx: 17 17\n",
      "test_idx : 21 21\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['windows4_std', 'windows5_std', 'windows12_var', 'windows12_std', 'windows4_var', 'windows5_var'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-69011bb49f63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0msub\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0monline_test_idx\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbetween\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m21\u001b[0m  \u001b[1;33m,\u001b[0m \u001b[1;36m24\u001b[0m  \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"---\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-5ca25be3af13>\u001b[0m in \u001b[0;36mget_train_model\u001b[1;34m(df_, m, m_type)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_idx :'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m  \u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m  \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# 最终确认\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mtrain_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mtrain_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mvalid_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2984\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2986\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"raise_missing\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1092\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"loc\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not in index\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['windows4_std', 'windows5_std', 'windows12_var', 'windows12_std', 'windows4_var', 'windows5_var'] not in index\""
     ]
    }
   ],
   "source": [
    "for month in [21,22,23,24]: \n",
    "    m_type = 'xgb' \n",
    "    judge = month-20\n",
    "    data = windows_feature(data,judge)\n",
    "    \n",
    "    data_df, stat_feat = get_stat_feature(data)\n",
    "    \n",
    "    win_feat = ['windows4_var','windows4_std','windows5_var','windows5_std','windows12_var','windows12_std']\n",
    "#     ,'windows6_var','windows6_std']\n",
    "#     qushi_feat = ['ratio2','differ2']\n",
    "    num_feat = ['regYear','regMonth'] + stat_feat +win_feat#,'windows_var','windows_std'\n",
    "    cate_feat = ['adcode','bodyType','model']\n",
    "    \n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "           \n",
    "    features = num_feat + cate_feat\n",
    "    print(len(features), len(set(features)))   \n",
    "    \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type)   \n",
    "    online_test_idx  = (data_df['mt'].between(21  , 24  ))\n",
    "    print(\"---\")\n",
    "    print(data.loc[(data.regMonth==month)].shape)\n",
    "    data.loc[(data.mt==month), 'salesVolume'   ] = sub['forecastVolum'].values\n",
    "    data.loc[(data.mt==(month)), 'label'      ] = sub['forecastVolum'].values\n",
    "    data.loc[(data.mt==(month)), 'pred_label'      ] = sub['forecastVolum'].values\n",
    "\n",
    "\n",
    "    # # sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "# # sub.columns = ['id','forecastVolum']\n",
    "# # sub[['id','forecastVolum']].round().astype(int).to_csv('submit/yulao_lgb.csv', index=False)\n",
    "best_score = online_score(data[online_test_idx]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.42s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 15.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "[0]\tvalidation_0-rmse:841.387\tvalidation_1-rmse:1046.81\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:840.854\tvalidation_1-rmse:1046.28\n",
      "[200]\tvalidation_0-rmse:839.416\tvalidation_1-rmse:1044.83\n",
      "[300]\tvalidation_0-rmse:835.586\tvalidation_1-rmse:1040.97\n",
      "[400]\tvalidation_0-rmse:825.694\tvalidation_1-rmse:1030.91\n",
      "[500]\tvalidation_0-rmse:801.738\tvalidation_1-rmse:1006.18\n",
      "[600]\tvalidation_0-rmse:750.162\tvalidation_1-rmse:951.587\n",
      "[700]\tvalidation_0-rmse:657.192\tvalidation_1-rmse:849.31\n",
      "[800]\tvalidation_0-rmse:524.723\tvalidation_1-rmse:696.311\n",
      "[900]\tvalidation_0-rmse:380.162\tvalidation_1-rmse:522.151\n",
      "[1000]\tvalidation_0-rmse:259.234\tvalidation_1-rmse:376.202\n",
      "[1100]\tvalidation_0-rmse:179.886\tvalidation_1-rmse:282.214\n",
      "[1200]\tvalidation_0-rmse:145.639\tvalidation_1-rmse:248.148\n",
      "[1300]\tvalidation_0-rmse:132.764\tvalidation_1-rmse:236.328\n",
      "[1400]\tvalidation_0-rmse:123.956\tvalidation_1-rmse:229.286\n",
      "[1500]\tvalidation_0-rmse:117.525\tvalidation_1-rmse:225.476\n",
      "[1600]\tvalidation_0-rmse:112.077\tvalidation_1-rmse:222.002\n",
      "[1700]\tvalidation_0-rmse:108.012\tvalidation_1-rmse:219.62\n",
      "[1800]\tvalidation_0-rmse:105.329\tvalidation_1-rmse:218.541\n",
      "[1900]\tvalidation_0-rmse:102.6\tvalidation_1-rmse:216.826\n",
      "[2000]\tvalidation_0-rmse:100.224\tvalidation_1-rmse:215.662\n",
      "[2100]\tvalidation_0-rmse:98.22\tvalidation_1-rmse:215.319\n",
      "[2200]\tvalidation_0-rmse:96.532\tvalidation_1-rmse:215.243\n",
      "[2300]\tvalidation_0-rmse:95.2175\tvalidation_1-rmse:214.773\n",
      "[2400]\tvalidation_0-rmse:93.5902\tvalidation_1-rmse:213.994\n",
      "[2500]\tvalidation_0-rmse:92.0521\tvalidation_1-rmse:213.366\n",
      "[2600]\tvalidation_0-rmse:90.7138\tvalidation_1-rmse:212.787\n",
      "[2700]\tvalidation_0-rmse:89.3237\tvalidation_1-rmse:212.099\n",
      "[2800]\tvalidation_0-rmse:88.0724\tvalidation_1-rmse:211.505\n",
      "[2900]\tvalidation_0-rmse:86.8326\tvalidation_1-rmse:211.486\n",
      "[3000]\tvalidation_0-rmse:85.4657\tvalidation_1-rmse:210.631\n",
      "[3100]\tvalidation_0-rmse:84.0276\tvalidation_1-rmse:210.01\n",
      "[3200]\tvalidation_0-rmse:82.8386\tvalidation_1-rmse:209.758\n",
      "[3300]\tvalidation_0-rmse:81.721\tvalidation_1-rmse:209.527\n",
      "[3400]\tvalidation_0-rmse:80.6025\tvalidation_1-rmse:209.511\n",
      "[3500]\tvalidation_0-rmse:79.6226\tvalidation_1-rmse:208.998\n",
      "[3600]\tvalidation_0-rmse:78.5413\tvalidation_1-rmse:208.909\n",
      "[3700]\tvalidation_0-rmse:77.562\tvalidation_1-rmse:208.716\n",
      "[3800]\tvalidation_0-rmse:76.4457\tvalidation_1-rmse:208.448\n",
      "[3900]\tvalidation_0-rmse:75.3537\tvalidation_1-rmse:208.069\n",
      "[3999]\tvalidation_0-rmse:74.4427\tvalidation_1-rmse:208.153\n",
      "0.7704167529810075\n",
      "valid mean: 623.15094\n",
      "true  mean: 649.3121212121212\n",
      "test  mean: 458.79114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.34s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "[0]\tvalidation_0-rmse:866.621\tvalidation_1-rmse:1007.38\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:866.089\tvalidation_1-rmse:1006.85\n",
      "[200]\tvalidation_0-rmse:864.653\tvalidation_1-rmse:1005.43\n",
      "[300]\tvalidation_0-rmse:860.828\tvalidation_1-rmse:1001.62\n",
      "[400]\tvalidation_0-rmse:850.935\tvalidation_1-rmse:991.753\n",
      "[500]\tvalidation_0-rmse:826.915\tvalidation_1-rmse:967.795\n",
      "[600]\tvalidation_0-rmse:774.935\tvalidation_1-rmse:915.746\n",
      "[700]\tvalidation_0-rmse:680.726\tvalidation_1-rmse:819.708\n",
      "[800]\tvalidation_0-rmse:544.976\tvalidation_1-rmse:682.224\n",
      "[900]\tvalidation_0-rmse:395.274\tvalidation_1-rmse:534.143\n",
      "[1000]\tvalidation_0-rmse:268.46\tvalidation_1-rmse:413.542\n",
      "[1100]\tvalidation_0-rmse:185.094\tvalidation_1-rmse:338.885\n",
      "[1200]\tvalidation_0-rmse:148.412\tvalidation_1-rmse:310.795\n",
      "[1300]\tvalidation_0-rmse:135.604\tvalidation_1-rmse:305.034\n",
      "[1400]\tvalidation_0-rmse:127.006\tvalidation_1-rmse:301.104\n",
      "[1500]\tvalidation_0-rmse:120.891\tvalidation_1-rmse:300.462\n",
      "Stopping. Best iteration:\n",
      "[1438]\tvalidation_0-rmse:124.346\tvalidation_1-rmse:300.103\n",
      "\n",
      "0.6135062378600542\n",
      "valid mean: 455.9764\n",
      "true  mean: 616.5537878787878\n",
      "test  mean: 287.6134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.28s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "[0]\tvalidation_0-rmse:881.709\tvalidation_1-rmse:1071.9\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:881.177\tvalidation_1-rmse:1071.36\n",
      "[200]\tvalidation_0-rmse:879.744\tvalidation_1-rmse:1069.89\n",
      "[300]\tvalidation_0-rmse:875.924\tvalidation_1-rmse:1065.98\n",
      "[400]\tvalidation_0-rmse:866.039\tvalidation_1-rmse:1055.8\n",
      "[500]\tvalidation_0-rmse:842.007\tvalidation_1-rmse:1030.84\n",
      "[600]\tvalidation_0-rmse:789.895\tvalidation_1-rmse:975.336\n",
      "[700]\tvalidation_0-rmse:694.969\tvalidation_1-rmse:871.571\n",
      "[800]\tvalidation_0-rmse:557.798\tvalidation_1-rmse:716.699\n",
      "[900]\tvalidation_0-rmse:405.58\tvalidation_1-rmse:542.434\n",
      "[1000]\tvalidation_0-rmse:276.35\tvalidation_1-rmse:397.253\n",
      "[1100]\tvalidation_0-rmse:190.667\tvalidation_1-rmse:305.207\n",
      "[1200]\tvalidation_0-rmse:154.971\tvalidation_1-rmse:271.795\n",
      "[1300]\tvalidation_0-rmse:140.976\tvalidation_1-rmse:261.29\n",
      "[1400]\tvalidation_0-rmse:131.097\tvalidation_1-rmse:253.97\n",
      "[1500]\tvalidation_0-rmse:123.573\tvalidation_1-rmse:249.8\n",
      "[1600]\tvalidation_0-rmse:117.466\tvalidation_1-rmse:246.017\n",
      "[1700]\tvalidation_0-rmse:113.772\tvalidation_1-rmse:243.643\n",
      "[1800]\tvalidation_0-rmse:110.041\tvalidation_1-rmse:242.037\n",
      "[1900]\tvalidation_0-rmse:106.974\tvalidation_1-rmse:240.72\n",
      "[2000]\tvalidation_0-rmse:104.46\tvalidation_1-rmse:240.411\n",
      "[2100]\tvalidation_0-rmse:102.371\tvalidation_1-rmse:240.26\n",
      "[2200]\tvalidation_0-rmse:100.264\tvalidation_1-rmse:239.565\n",
      "[2300]\tvalidation_0-rmse:98.5715\tvalidation_1-rmse:239.589\n",
      "[2400]\tvalidation_0-rmse:97.1418\tvalidation_1-rmse:239.243\n",
      "[2500]\tvalidation_0-rmse:95.5244\tvalidation_1-rmse:238.933\n",
      "[2600]\tvalidation_0-rmse:94.227\tvalidation_1-rmse:238.502\n",
      "[2700]\tvalidation_0-rmse:92.788\tvalidation_1-rmse:238.087\n",
      "Stopping. Best iteration:\n",
      "[2684]\tvalidation_0-rmse:93.0052\tvalidation_1-rmse:237.949\n",
      "\n",
      "0.7218989650293122\n",
      "valid mean: 568.9693\n",
      "true  mean: 673.0143939393939\n",
      "test  mean: 337.8751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.29s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "[0]\tvalidation_0-rmse:900.66\tvalidation_1-rmse:1451.31\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:900.128\tvalidation_1-rmse:1450.78\n",
      "[200]\tvalidation_0-rmse:898.694\tvalidation_1-rmse:1449.33\n",
      "[300]\tvalidation_0-rmse:894.87\tvalidation_1-rmse:1445.44\n",
      "[400]\tvalidation_0-rmse:884.963\tvalidation_1-rmse:1435.29\n",
      "[500]\tvalidation_0-rmse:860.829\tvalidation_1-rmse:1410.04\n",
      "[600]\tvalidation_0-rmse:808.295\tvalidation_1-rmse:1353.21\n",
      "[700]\tvalidation_0-rmse:712.128\tvalidation_1-rmse:1245.94\n",
      "[800]\tvalidation_0-rmse:572.214\tvalidation_1-rmse:1087.8\n",
      "[900]\tvalidation_0-rmse:415.731\tvalidation_1-rmse:924.84\n",
      "[1000]\tvalidation_0-rmse:282.041\tvalidation_1-rmse:806.888\n",
      "[1100]\tvalidation_0-rmse:193.642\tvalidation_1-rmse:738.259\n",
      "[1200]\tvalidation_0-rmse:155.982\tvalidation_1-rmse:712.916\n",
      "[1300]\tvalidation_0-rmse:143.821\tvalidation_1-rmse:711.15\n",
      "Stopping. Best iteration:\n",
      "[1263]\tvalidation_0-rmse:147.131\tvalidation_1-rmse:709.407\n",
      "\n",
      "0.41897786888760846\n",
      "valid mean: 498.20517\n",
      "true  mean: 899.8204545454546\n",
      "test  mean: 324.48294\n"
     ]
    }
   ],
   "source": [
    "for month in [21,22,23,24]: \n",
    "    m_type = 'xgb' \n",
    "    \n",
    "    data_df, stat_feat = get_stat_feature(data)\n",
    "    \n",
    "    win_feat = ['windows4_var','windows4_std','windows5_var','windows5_std','windows6_var','windows6_std']\n",
    "#     qushi_feat = ['ratio2','differ2']\n",
    "    num_feat = ['regYear','regMonth'] + stat_feat +win_feat#,'windows_var','windows_std'\n",
    "    cate_feat = ['adcode','bodyType','model']\n",
    "    \n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "           \n",
    "    features = num_feat + cate_feat\n",
    "    print(len(features), len(set(features)))   \n",
    "    \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type)   \n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'label'      ] = sub['forecastVolum'].values\t\n",
    "sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub.columns = ['id','forecastVolum']\n",
    "sub[['id','forecastVolum']].round().astype(int).to_csv('submit/yulao_xgb.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 9 20\n",
      "train_idx: 9 16\n",
      "valid_idx: 17 17\n",
      "test_idx : 21 21\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 128712\tvalid_1's l2: 98700.9\n",
      "[200]\ttraining's l2: 41958.5\tvalid_1's l2: 38841.5\n",
      "[300]\ttraining's l2: 23711.2\tvalid_1's l2: 28937.2\n",
      "[400]\ttraining's l2: 17316.6\tvalid_1's l2: 26511.4\n",
      "[500]\ttraining's l2: 13789.8\tvalid_1's l2: 25838.3\n",
      "[600]\ttraining's l2: 11344.6\tvalid_1's l2: 25413.5\n",
      "[700]\ttraining's l2: 9716.53\tvalid_1's l2: 25005.3\n",
      "[800]\ttraining's l2: 8521.85\tvalid_1's l2: 24786.1\n",
      "[900]\ttraining's l2: 7601.14\tvalid_1's l2: 24786.9\n",
      "[1000]\ttraining's l2: 6807.82\tvalid_1's l2: 24710.5\n",
      "[1100]\ttraining's l2: 6154.66\tvalid_1's l2: 24588.3\n",
      "[1200]\ttraining's l2: 5603.01\tvalid_1's l2: 24436.2\n",
      "[1300]\ttraining's l2: 5128.15\tvalid_1's l2: 24299.6\n",
      "[1400]\ttraining's l2: 4756.47\tvalid_1's l2: 24098.7\n",
      "[1500]\ttraining's l2: 4411.44\tvalid_1's l2: 23997.3\n",
      "[1600]\ttraining's l2: 4081.94\tvalid_1's l2: 23915.1\n",
      "[1700]\ttraining's l2: 3801.56\tvalid_1's l2: 23785.2\n",
      "[1800]\ttraining's l2: 3551.93\tvalid_1's l2: 23733.7\n",
      "[1900]\ttraining's l2: 3322.77\tvalid_1's l2: 23685.3\n",
      "[2000]\ttraining's l2: 3105.34\tvalid_1's l2: 23583.8\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's l2: 3105.34\tvalid_1's l2: 23583.8\n",
      "0.7973272983520384\n",
      "valid mean: 497.2429189926641\n",
      "true  mean: 534.5318181818182\n",
      "test  mean: 641.6628984132291\n",
      "(1320, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 9 21\n",
      "train_idx: 9 17\n",
      "valid_idx: 18 18\n",
      "test_idx : 22 22\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 124896\tvalid_1's l2: 101622\n",
      "[200]\ttraining's l2: 41221.5\tvalid_1's l2: 40668.4\n",
      "[300]\ttraining's l2: 23551.2\tvalid_1's l2: 30796.4\n",
      "[400]\ttraining's l2: 17247.5\tvalid_1's l2: 28629.1\n",
      "[500]\ttraining's l2: 13644.1\tvalid_1's l2: 28447.5\n",
      "[600]\ttraining's l2: 11311.3\tvalid_1's l2: 28214.8\n",
      "[700]\ttraining's l2: 9665.8\tvalid_1's l2: 28306.6\n",
      "Early stopping, best iteration is:\n",
      "[602]\ttraining's l2: 11275.5\tvalid_1's l2: 28202.4\n",
      "0.7483585609319627\n",
      "valid mean: 547.3275192104005\n",
      "true  mean: 523.3159090909091\n",
      "test  mean: 648.8015280661291\n",
      "(1320, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 9 22\n",
      "train_idx: 9 18\n",
      "valid_idx: 19 19\n",
      "test_idx : 23 23\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 121129\tvalid_1's l2: 101400\n",
      "[200]\ttraining's l2: 40304.7\tvalid_1's l2: 38675.6\n",
      "[300]\ttraining's l2: 23218.8\tvalid_1's l2: 27340.3\n",
      "[400]\ttraining's l2: 17179.7\tvalid_1's l2: 24853.9\n",
      "[500]\ttraining's l2: 13713.1\tvalid_1's l2: 23959.2\n",
      "[600]\ttraining's l2: 11471.2\tvalid_1's l2: 23400.8\n",
      "[700]\ttraining's l2: 9962.11\tvalid_1's l2: 22931.2\n",
      "[800]\ttraining's l2: 8881.21\tvalid_1's l2: 22567.1\n",
      "[900]\ttraining's l2: 8007.93\tvalid_1's l2: 22383.6\n",
      "[1000]\ttraining's l2: 7299.37\tvalid_1's l2: 22289.3\n",
      "[1100]\ttraining's l2: 6668.06\tvalid_1's l2: 22270.3\n",
      "[1200]\ttraining's l2: 6149.12\tvalid_1's l2: 22150.4\n",
      "Early stopping, best iteration is:\n",
      "[1196]\ttraining's l2: 6170.05\tvalid_1's l2: 22128.1\n",
      "0.7468931536269028\n",
      "valid mean: 560.7094271141314\n",
      "true  mean: 552.2295454545455\n",
      "test  mean: 734.8046071367794\n",
      "(1320, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 9 23\n",
      "train_idx: 9 19\n",
      "valid_idx: 20 20\n",
      "test_idx : 24 24\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 118772\tvalid_1's l2: 145395\n",
      "[200]\ttraining's l2: 39386.3\tvalid_1's l2: 51071.7\n",
      "[300]\ttraining's l2: 22711.1\tvalid_1's l2: 32006.2\n",
      "[400]\ttraining's l2: 17040\tvalid_1's l2: 27020.4\n",
      "[500]\ttraining's l2: 13774.6\tvalid_1's l2: 25125.4\n",
      "[600]\ttraining's l2: 11675.5\tvalid_1's l2: 24421\n",
      "[700]\ttraining's l2: 10208\tvalid_1's l2: 24129.7\n",
      "[800]\ttraining's l2: 9205.22\tvalid_1's l2: 23964.6\n",
      "[900]\ttraining's l2: 8388.5\tvalid_1's l2: 23799.9\n",
      "[1000]\ttraining's l2: 7727.56\tvalid_1's l2: 23768.7\n",
      "Early stopping, best iteration is:\n",
      "[989]\ttraining's l2: 7801.96\tvalid_1's l2: 23734.8\n",
      "0.7917019686244774\n",
      "valid mean: 595.4352742803294\n",
      "true  mean: 620.0212121212121\n",
      "test  mean: 856.408786058386\n",
      "(1320, 2)\n"
     ]
    }
   ],
   "source": [
    "for month in [21,22,23,24]: \n",
    "    m_type = 'lgb' \n",
    "    \n",
    "    data_df, stat_feat = get_stat_feature(data)\n",
    "    \n",
    "    num_feat = ['regYear','regMonth'] + stat_feat\n",
    "    cate_feat = ['adcode','bodyType','model']\n",
    "    \n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "           \n",
    "    features = num_feat + cate_feat\n",
    "#     print(len(features), len(set(features)))   \n",
    "    \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type)   \n",
    "    data.loc[(data.mt==month), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.mt==month), 'label'      ] = sub['forecastVolum'].values\n",
    "    data.loc[(data.mt==(month)), 'pred_label'      ] = sub['forecastVolum'].values\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "# sub.columns = ['id','forecastVolum']\n",
    "# sub[['id','forecastVolum']].round().astype(int).to_csv('CCF_sales.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 86584.9\tvalid_1's l2: 151719\n",
      "[200]\ttraining's l2: 27784.3\tvalid_1's l2: 71704.5\n",
      "[300]\ttraining's l2: 14902.5\tvalid_1's l2: 57361.3\n",
      "[400]\ttraining's l2: 10243.5\tvalid_1's l2: 52224.7\n",
      "[500]\ttraining's l2: 7869.38\tvalid_1's l2: 50304.7\n",
      "[600]\ttraining's l2: 6385.06\tvalid_1's l2: 49569.7\n",
      "[700]\ttraining's l2: 5380.65\tvalid_1's l2: 48911.9\n",
      "[800]\ttraining's l2: 4634.41\tvalid_1's l2: 48274\n",
      "[900]\ttraining's l2: 4071.47\tvalid_1's l2: 48026.2\n",
      "[1000]\ttraining's l2: 3625\tvalid_1's l2: 47641.9\n",
      "[1100]\ttraining's l2: 3253.2\tvalid_1's l2: 47425.4\n",
      "[1200]\ttraining's l2: 2928.61\tvalid_1's l2: 47143.3\n",
      "[1300]\ttraining's l2: 2653.04\tvalid_1's l2: 46870.8\n",
      "[1400]\ttraining's l2: 2414.07\tvalid_1's l2: 46669.9\n",
      "[1500]\ttraining's l2: 2207.68\tvalid_1's l2: 46487.6\n",
      "[1600]\ttraining's l2: 2028.06\tvalid_1's l2: 46336.7\n",
      "[1700]\ttraining's l2: 1876.96\tvalid_1's l2: 46208.4\n",
      "[1800]\ttraining's l2: 1749.37\tvalid_1's l2: 46176.2\n",
      "[1900]\ttraining's l2: 1632.35\tvalid_1's l2: 46079.2\n",
      "[2000]\ttraining's l2: 1525.02\tvalid_1's l2: 46029.5\n",
      "[2100]\ttraining's l2: 1420.06\tvalid_1's l2: 45984.2\n",
      "[2200]\ttraining's l2: 1322.58\tvalid_1's l2: 45885.2\n",
      "Early stopping, best iteration is:\n",
      "[2188]\ttraining's l2: 1333.16\tvalid_1's l2: 45878\n",
      "0.7657263463789578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 90083.5\tvalid_1's l2: 118412\n",
      "[200]\ttraining's l2: 28475.8\tvalid_1's l2: 59906.1\n",
      "[300]\ttraining's l2: 15309.6\tvalid_1's l2: 52080.3\n",
      "[400]\ttraining's l2: 10785.7\tvalid_1's l2: 50404.3\n",
      "[500]\ttraining's l2: 8324.54\tvalid_1's l2: 49632.1\n",
      "[600]\ttraining's l2: 6828.3\tvalid_1's l2: 49046.4\n",
      "[700]\ttraining's l2: 5813.9\tvalid_1's l2: 48997.8\n",
      "Early stopping, best iteration is:\n",
      "[648]\ttraining's l2: 6301.83\tvalid_1's l2: 48762.4\n",
      "0.7352932759641437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 93591.6\tvalid_1's l2: 135289\n",
      "[200]\ttraining's l2: 29582.9\tvalid_1's l2: 52574.8\n",
      "[300]\ttraining's l2: 15864.8\tvalid_1's l2: 39181.2\n",
      "[400]\ttraining's l2: 11154.7\tvalid_1's l2: 36023.5\n",
      "[500]\ttraining's l2: 8739.67\tvalid_1's l2: 35331.5\n",
      "[600]\ttraining's l2: 7173.39\tvalid_1's l2: 34526.5\n",
      "[700]\ttraining's l2: 6126.06\tvalid_1's l2: 34402.5\n",
      "[800]\ttraining's l2: 5347.97\tvalid_1's l2: 34349\n",
      "[900]\ttraining's l2: 4770.82\tvalid_1's l2: 34426\n",
      "Early stopping, best iteration is:\n",
      "[806]\ttraining's l2: 5308.31\tvalid_1's l2: 34325.1\n",
      "0.7811424903161602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 96023.9\tvalid_1's l2: 552065\n",
      "[200]\ttraining's l2: 29709.3\tvalid_1's l2: 354551\n",
      "[300]\ttraining's l2: 16067.9\tvalid_1's l2: 299015\n",
      "[400]\ttraining's l2: 11490.5\tvalid_1's l2: 282547\n",
      "[500]\ttraining's l2: 9067.98\tvalid_1's l2: 274322\n",
      "[600]\ttraining's l2: 7522.51\tvalid_1's l2: 271372\n",
      "[700]\ttraining's l2: 6477.28\tvalid_1's l2: 271395\n",
      "Early stopping, best iteration is:\n",
      "[658]\ttraining's l2: 6879.88\tvalid_1's l2: 270441\n",
      "0.6226761089064834\n"
     ]
    }
   ],
   "source": [
    "for month in [21,22,23,24]: \n",
    "    m_type = 'lgb' \n",
    "    \n",
    "    data_df, stat_feat = get_stat_feature(data)\n",
    "    \n",
    "    num_feat = ['regYear','regMonth','popularity'] + stat_feat\n",
    "    cate_feat = ['adcode','bodyType','model']\n",
    "    \n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "           \n",
    "    features = num_feat + cate_feat\n",
    "#     print(len(features), len(set(features)))   \n",
    "    \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type)   \n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'label'      ] = sub['forecastVolum'].values\n",
    "#     data.loc[(data.mt==(month)), 'pred_label'      ] = sub['forecastVolum'].values\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub.columns = ['id','forecastVolum']\n",
    "# sub[['id','forecastVolum']].round().astype(int).to_csv('CCF_sales.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[['id','forecastVolum']].round().astype(int).to_csv('CCF_sales0914.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 7291.26\tvalid_1's l2: 37932.3\n",
      "[200]\ttraining's l2: 3715.93\tvalid_1's l2: 35716.9\n",
      "[300]\ttraining's l2: 2515.27\tvalid_1's l2: 35194.8\n",
      "[400]\ttraining's l2: 1831.38\tvalid_1's l2: 34788.8\n",
      "[500]\ttraining's l2: 1397.64\tvalid_1's l2: 34608.6\n",
      "[600]\ttraining's l2: 1065.51\tvalid_1's l2: 34527.1\n",
      "[700]\ttraining's l2: 849.095\tvalid_1's l2: 34415.2\n",
      "[800]\ttraining's l2: 679.238\tvalid_1's l2: 34333.1\n",
      "[900]\ttraining's l2: 545.247\tvalid_1's l2: 34326.4\n",
      "Early stopping, best iteration is:\n",
      "[838]\ttraining's l2: 624.086\tvalid_1's l2: 34316.6\n",
      "0.7559303097480222\n",
      "valid mean: 602.8972278482273\n",
      "true  mean: 649.3121212121212\n",
      "test  mean: 493.9801201875369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 7936.91\tvalid_1's l2: 41558.5\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's l2: 10761.5\tvalid_1's l2: 41117.3\n",
      "0.7414955122487169\n",
      "valid mean: 623.4500376146684\n",
      "true  mean: 616.5537878787878\n",
      "test  mean: 324.6451813135614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 8653.84\tvalid_1's l2: 32560.4\n",
      "[200]\ttraining's l2: 4627.91\tvalid_1's l2: 32133.2\n",
      "Early stopping, best iteration is:\n",
      "[155]\ttraining's l2: 5757.15\tvalid_1's l2: 31853.4\n",
      "0.7794578141087838\n",
      "valid mean: 639.6227869473659\n",
      "true  mean: 673.0143939393939\n",
      "test  mean: 479.55100257280156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 9306.24\tvalid_1's l2: 302435\n",
      "[200]\ttraining's l2: 5107.21\tvalid_1's l2: 292129\n",
      "[300]\ttraining's l2: 3583.18\tvalid_1's l2: 289373\n",
      "[400]\ttraining's l2: 2709.06\tvalid_1's l2: 288389\n",
      "[500]\ttraining's l2: 2162.77\tvalid_1's l2: 287983\n",
      "[600]\ttraining's l2: 1746.75\tvalid_1's l2: 287504\n",
      "[700]\ttraining's l2: 1446.22\tvalid_1's l2: 287029\n",
      "[800]\ttraining's l2: 1196.94\tvalid_1's l2: 286429\n",
      "[900]\ttraining's l2: 1008.26\tvalid_1's l2: 286030\n",
      "Early stopping, best iteration is:\n",
      "[856]\ttraining's l2: 1089.91\tvalid_1's l2: 286004\n",
      "0.588139278724323\n",
      "valid mean: 645.3917897243205\n",
      "true  mean: 899.8204545454546\n",
      "test  mean: 468.0356962498267\n"
     ]
    }
   ],
   "source": [
    "for month in [25,26,27,28]: \n",
    "    m_type = 'lgb' \n",
    "    \n",
    "    data_df, stat_feat = get_stat_feature(data)\n",
    "    \n",
    "    num_feat = ['regYear'] + stat_feat\n",
    "    cate_feat = ['adcode','bodyType','model','regMonth']\n",
    "    \n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "           \n",
    "    features = num_feat + cate_feat\n",
    "    print(len(features), len(set(features)))   \n",
    "    \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type)   \n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'label'      ] = sub['forecastVolum'].values\n",
    "sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub.columns = ['id','forecastVolum']\n",
    "# sub[['id','forecastVolum']].round().astype(int).to_csv('CCF_sales.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
