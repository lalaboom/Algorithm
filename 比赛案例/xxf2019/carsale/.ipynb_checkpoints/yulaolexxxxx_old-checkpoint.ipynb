{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-2-027fb5b461bb>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-027fb5b461bb>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    特征：\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "特征：\n",
    "   'label','popularity','carCommentVolum','newsReplyVolum'平移了12个月\n",
    "    train:\n",
    "        1,  2,  3,  4,  5,  6,  7,  8,  9,  10,  11,  12\n",
    "        13, 14, 15, 16, 17, 18, 19, 20, 21, 22,  23,  24 \n",
    "        \n",
    "    test: 21,22,23,24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import os \n",
    "# import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl = LabelEncoder()\n",
    "import datetime\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adcode</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>forecastVolum</th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>province</th>\n",
       "      <th>regMonth</th>\n",
       "      <th>regYear</th>\n",
       "      <th>salesVolume</th>\n",
       "      <th>popularity</th>\n",
       "      <th>carCommentVolum</th>\n",
       "      <th>newsReplyVolum</th>\n",
       "      <th>label</th>\n",
       "      <th>mt</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>36955</td>\n",
       "      <td>350000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5364</td>\n",
       "      <td>59</td>\n",
       "      <td>福建</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36956</td>\n",
       "      <td>210000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5365</td>\n",
       "      <td>59</td>\n",
       "      <td>辽宁</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36957</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5366</td>\n",
       "      <td>59</td>\n",
       "      <td>重庆</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36958</td>\n",
       "      <td>610000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5367</td>\n",
       "      <td>59</td>\n",
       "      <td>陕西</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36959</td>\n",
       "      <td>230000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5368</td>\n",
       "      <td>59</td>\n",
       "      <td>黑龙江</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       adcode  bodyType  forecastVolum    id  model province  regMonth  \\\n",
       "36955  350000         0            NaN  5364     59       福建         4   \n",
       "36956  210000         0            NaN  5365     59       辽宁         4   \n",
       "36957  500000         0            NaN  5366     59       重庆         4   \n",
       "36958  610000         0            NaN  5367     59       陕西         4   \n",
       "36959  230000         0            NaN  5368     59      黑龙江         4   \n",
       "\n",
       "       regYear  salesVolume  popularity  carCommentVolum  newsReplyVolum  \\\n",
       "36955     2018          NaN         NaN              NaN             NaN   \n",
       "36956     2018          NaN         NaN              NaN             NaN   \n",
       "36957     2018          NaN         NaN              NaN             NaN   \n",
       "36958     2018          NaN         NaN              NaN             NaN   \n",
       "36959     2018          NaN         NaN              NaN             NaN   \n",
       "\n",
       "       label  mt  pred_label  \n",
       "36955    NaN  28           0  \n",
       "36956    NaN  28           0  \n",
       "36957    NaN  28           0  \n",
       "36958    NaN  28           0  \n",
       "36959    NaN  28           0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path  = './ccf_car/'\n",
    "train_sales  = pd.read_csv('train_sales_data.csv')\n",
    "\n",
    "\n",
    "train_search = pd.read_csv('train_search_data.csv')\n",
    "train_user   = pd.read_csv('train_user_reply_data.csv')\n",
    "evaluation_public = pd.read_csv('evaluation_public.csv')\n",
    "# submit_example    = pd.read_csv('submit_example.csv')\n",
    "data = pd.concat([train_sales, evaluation_public], ignore_index=True)\n",
    "data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth'])\n",
    "data['label'] = data['salesVolume']\n",
    "data['id'] = data['id'].fillna(0).astype(int)\n",
    "data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "#索引-->value\n",
    "#LabelEncoder\n",
    "for i in ['bodyType', 'model']:\n",
    "    data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "    #key-->value\n",
    "data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']\n",
    "initial_key_list = ['adcode','bodyType','forecastVolum','id','model','province','regMonth','regYear','salesVolume','popularity','carCommentVolum','newsReplyVolum'\t,'label','mt']\n",
    "data = data[initial_key_list].copy()\n",
    "data['pred_label'] = 0\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cluster(df_,pred_month): \n",
    "    df_['cluster_label']  =-1\n",
    "    df = df_[df_['mt']<pred_month]\n",
    "    df= df[['adcode','model','mt','label']].set_index(['model','adcode','mt']).reset_index()\n",
    "    kmeans = KMeans(n_clusters = 3) \n",
    "    kmeans.fit(df.values)\n",
    "    df_.loc[df_['mt']<pred_month,'cluster_label'] =  kmeans.labels_\n",
    "#     print(df.head())\n",
    "#     df = df.merge(df,'left',on = ['adcode','model','mt','label'])\n",
    "    return df_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windows_feature(data):\n",
    "#     if (judge >1):\n",
    "    print(\"windows_var_features start\")\n",
    "    df = data.copy()\n",
    "    df_all = pd.DataFrame()\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    model_adcode = list(df.model_adcode.unique())\n",
    "    for i in tqdm(model_adcode):\n",
    "        idx = (df['model_adcode']==i)\n",
    "        df2 = df[idx] \n",
    "\n",
    "        df2['windows3_var'] = df2['label'].rolling(3).var()\n",
    "        df2['windows5_var'] = df2['label'].rolling(5).var()\n",
    "        df2['windows7_var'] = df2['label'].rolling(7).var()\n",
    "\n",
    "        df2['windows3_var'] = df2['windows3_var'].rolling(3).var()\n",
    "        df2['windows5_var'] = df2['windows5_var'].rolling(5).var()\n",
    "        df2['windows7_var'] = df2['windows7_var'].rolling(7).var()\n",
    "\n",
    "        df_all = pd.concat([df_all, df2], ignore_index=True)\n",
    "    data = data.merge(df_all, 'left', on=['cluster_label','adcode','bodyType','forecastVolum','id','model','province','regMonth','regYear','salesVolume','popularity','carCommentVolum','newsReplyVolum','pred_label','label','mt'])\n",
    "    print(\"windows_var_features end\")\n",
    "    return data\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat_feature(df_):   \n",
    "    df = df_.copy()\n",
    "    stat_feat = []\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "    for col in tqdm(['label','popularity','newsReplyVolum']):#,'newsReplyVolum'\n",
    "    # shift\n",
    "        for i in [1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])\n",
    "# \n",
    "#     for i in [1]: #本月销量和前1-3,12个月相减\n",
    "#         df[\"differ_{}_{}\".format(col,i)] = df['{}'.format(col)] -df['shift_model_adcode_mt_{}_{}'.format(col,i)]\n",
    "#         df[\"differ2_{}_{}\".format(col,i)] = df[\"differ_{}_{}\".format(col,i)]-df.groupby('model_adcode')[\"differ_{}_{}\".format(col,i)].shift(1)\n",
    "#         stat_feat.append(\"differ2_{}_{}\".format(col,i))\n",
    "\n",
    "#         df[\"ratio_{}_{}\".format(col,i)] = df['{}'.format(col)] /df['shift_model_adcode_mt_{}_{}'.format(col,i)]\n",
    "#         df[\"ratio2_{}_{}\".format(col,i)] = df[\"ratio_{}_{}\".format(col,i)]/df.groupby('model_adcode')[\"ratio_{}_{}\".format(col,i)].shift(1)\n",
    "#         stat_feat.append(\"ratio2_{}_{}\".format(col,i))\n",
    "    return df,stat_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat_feature2(df_):  #bodytype+省份\n",
    "    df = df_.copy()\n",
    "    print(df.shape)\n",
    "    stat2_feat = []\n",
    "    df['body_adcode'] = df['adcode'] + df['bodyType']\n",
    "    df['body_adcode_mt'] = df['body_adcode'] * 100 + df['mt']\n",
    "    df2 = df.copy()\n",
    "    for col in tqdm(['label','popularity','newsReplyVolum']):\n",
    "        df = df.groupby(['bodyType','adcode','body_adcode','mt','body_adcode_mt'])[col].mean().reset_index()\n",
    "        for i in [1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "            df['shift_{}_{}_body_adcode'.format(col,i)] = df.groupby('body_adcode')[col].shift(i)\n",
    "            stat2_feat.append('shift_{}_{}_body_adcode'.format(col,i))\n",
    "        df2 = df2.merge(df,'left',on = ['bodyType','adcode','mt','body_adcode_mt','body_adcode',col])\n",
    "        df = df2.copy()\n",
    "    \n",
    "    return df2,stat2_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat_feature3(df_):  #省份\n",
    "    df = df_.copy()\n",
    "    print(df.shape)\n",
    "    stat3_feat = []\n",
    "#     df['adcode'] = df['adcode'] + df['bodyType']\n",
    "    df['adcode_mt'] = df['adcode'] * 100 + df['mt']\n",
    "    df2 = df.copy()\n",
    "    for col in tqdm(['label','popularity','newsReplyVolum']):\n",
    "        df = df.groupby(['adcode','mt','adcode_mt'])[col].mean().reset_index()\n",
    "        for i in [1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "            df['shift_{}_{}_adcode'.format(col,i)] = df.groupby('adcode')[col].shift(i)\n",
    "            stat3_feat.append('shift_{}_{}_adcode'.format(col,i))\n",
    "        df2 = df2.merge(df,'left',on = ['adcode','mt','adcode_mt',col])\n",
    "        df = df2.copy()\n",
    "    return df2,stat3_feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_score(data, pred='pred_label', label='true_sales', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    y = pd.read_csv(\"valid_data_y.csv\")\n",
    "    data = data.merge(y, 'left', on=['id'])\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb'):   \n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.01, min_child_samples=1, random_state=1024,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,\n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "                  \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              categorical_feature=cate_feat, \n",
    "              early_stopping_rounds=100, verbose=100)      \n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.01, n_estimators=4000, \n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9, \n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse' \n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              early_stopping_rounds=100, verbose=100)   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_model(df_, m, m_type):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分\n",
    "    st = 9\n",
    "    all_idx   = (df['mt'].between(st , m-1))\n",
    "    train_idx = (df['mt'].between(st , m-5))\n",
    "    valid_idx = (df['mt'].between(m-4, m-4))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    \n",
    "    print('all_idx  :',st ,m-1)\n",
    "    print('train_idx:',st ,m-5)\n",
    "    print('valid_idx:',m-4,m-4)\n",
    "    print('test_idx :',m  ,m  )  \n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['label']   \n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type)  \n",
    "    # offline\n",
    "    df['pred_label'] = model.predict(df[features])\n",
    "    best_score = valid_score(df[valid_idx]) \n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'], categorical_feature=cate_feat)\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'])\n",
    "    df['forecastVolum'] = model.predict(df[features])\n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    print(\"--------------------------\")\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    print(sub.shape)\n",
    "    return sub,df[valid_idx]['pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows_var_features start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1320/1320 [00:18<00:00, 71.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows_var_features end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36960, 93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36960, 131)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 26.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxxxxxxxxxxxxxxxxx\n",
      "119 119\n",
      "all_idx  : 9 24\n",
      "train_idx: 9 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "[0]\tvalidation_0-rmse:984.025\tvalidation_1-rmse:1046.81\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:983.499\tvalidation_1-rmse:1046.28\n",
      "[200]\tvalidation_0-rmse:982.078\tvalidation_1-rmse:1044.83\n",
      "[300]\tvalidation_0-rmse:978.285\tvalidation_1-rmse:1040.96\n",
      "[400]\tvalidation_0-rmse:968.429\tvalidation_1-rmse:1030.88\n",
      "[500]\tvalidation_0-rmse:944.263\tvalidation_1-rmse:1006.08\n",
      "[600]\tvalidation_0-rmse:891.055\tvalidation_1-rmse:950.937\n",
      "[700]\tvalidation_0-rmse:791.954\tvalidation_1-rmse:846.635\n",
      "[800]\tvalidation_0-rmse:644.625\tvalidation_1-rmse:689.918\n",
      "[900]\tvalidation_0-rmse:476.579\tvalidation_1-rmse:509.867\n",
      "[1000]\tvalidation_0-rmse:328.205\tvalidation_1-rmse:352.117\n",
      "[1100]\tvalidation_0-rmse:227.934\tvalidation_1-rmse:245.034\n",
      "[1200]\tvalidation_0-rmse:178.756\tvalidation_1-rmse:199.203\n",
      "[1300]\tvalidation_0-rmse:161.428\tvalidation_1-rmse:187.213\n",
      "[1400]\tvalidation_0-rmse:151.744\tvalidation_1-rmse:180.692\n",
      "[1500]\tvalidation_0-rmse:142.629\tvalidation_1-rmse:175.77\n",
      "[1600]\tvalidation_0-rmse:135.535\tvalidation_1-rmse:173.146\n",
      "[1700]\tvalidation_0-rmse:129.538\tvalidation_1-rmse:171.472\n",
      "[1800]\tvalidation_0-rmse:125.261\tvalidation_1-rmse:169.602\n",
      "[1900]\tvalidation_0-rmse:121.647\tvalidation_1-rmse:168.046\n",
      "[2000]\tvalidation_0-rmse:118.79\tvalidation_1-rmse:167.208\n",
      "[2100]\tvalidation_0-rmse:115.98\tvalidation_1-rmse:167.025\n",
      "Stopping. Best iteration:\n",
      "[2052]\tvalidation_0-rmse:117.054\tvalidation_1-rmse:166.48\n",
      "\n",
      "0.7967062200409829\n",
      "valid mean: 623.9385\n",
      "true  mean: 649.3121212121212\n",
      "test  mean: 499.88367\n",
      "--------------------------\n",
      "(1320, 2)\n",
      "---\n",
      "(0, 16)\n",
      "windows_var_features start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1320/1320 [00:18<00:00, 70.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows_var_features end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36960, 93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36960, 131)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 27.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxxxxxxxxxxxxxxxxx\n",
      "119 119\n",
      "all_idx  : 9 25\n",
      "train_idx: 9 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "[0]\tvalidation_0-rmse:988.997\tvalidation_1-rmse:1007.38\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:988.469\tvalidation_1-rmse:1006.85\n",
      "[200]\tvalidation_0-rmse:987.047\tvalidation_1-rmse:1005.42\n",
      "[300]\tvalidation_0-rmse:983.248\tvalidation_1-rmse:1001.6\n",
      "[400]\tvalidation_0-rmse:973.373\tvalidation_1-rmse:991.644\n",
      "[500]\tvalidation_0-rmse:949.143\tvalidation_1-rmse:967.031\n",
      "[600]\tvalidation_0-rmse:895.754\tvalidation_1-rmse:912.226\n",
      "[700]\tvalidation_0-rmse:796.173\tvalidation_1-rmse:808.349\n",
      "[800]\tvalidation_0-rmse:647.721\tvalidation_1-rmse:651.84\n",
      "[900]\tvalidation_0-rmse:477.889\tvalidation_1-rmse:473.06\n",
      "[1000]\tvalidation_0-rmse:328.341\tvalidation_1-rmse:324.26\n",
      "[1100]\tvalidation_0-rmse:226.527\tvalidation_1-rmse:233.849\n",
      "[1200]\tvalidation_0-rmse:177.744\tvalidation_1-rmse:202.648\n",
      "[1300]\tvalidation_0-rmse:159.845\tvalidation_1-rmse:196.745\n",
      "[1400]\tvalidation_0-rmse:150.114\tvalidation_1-rmse:195.68\n",
      "Stopping. Best iteration:\n",
      "[1363]\tvalidation_0-rmse:153.063\tvalidation_1-rmse:195.355\n",
      "\n",
      "0.7440578871402248\n",
      "valid mean: 637.7658\n",
      "true  mean: 616.5537878787878\n",
      "test  mean: 347.62222\n",
      "--------------------------\n",
      "(1320, 2)\n",
      "---\n",
      "(0, 16)\n",
      "windows_var_features start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1320/1320 [00:19<00:00, 67.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows_var_features end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36960, 93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36960, 131)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 27.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxxxxxxxxxxxxxxxxx\n",
      "119 119\n",
      "all_idx  : 9 26\n",
      "train_idx: 9 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "[0]\tvalidation_0-rmse:990.321\tvalidation_1-rmse:1071.9\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:989.794\tvalidation_1-rmse:1071.36\n",
      "[200]\tvalidation_0-rmse:988.371\tvalidation_1-rmse:1069.89\n",
      "[300]\tvalidation_0-rmse:984.571\tvalidation_1-rmse:1065.97\n",
      "[400]\tvalidation_0-rmse:974.691\tvalidation_1-rmse:1055.74\n",
      "[500]\tvalidation_0-rmse:950.448\tvalidation_1-rmse:1030.42\n",
      "[600]\tvalidation_0-rmse:897.001\tvalidation_1-rmse:973.659\n",
      "[700]\tvalidation_0-rmse:797.254\tvalidation_1-rmse:865.286\n",
      "[800]\tvalidation_0-rmse:648.599\tvalidation_1-rmse:698.942\n",
      "[900]\tvalidation_0-rmse:478.041\tvalidation_1-rmse:505.698\n",
      "[1000]\tvalidation_0-rmse:328.048\tvalidation_1-rmse:342.142\n",
      "[1100]\tvalidation_0-rmse:228.039\tvalidation_1-rmse:241.1\n",
      "[1200]\tvalidation_0-rmse:179.391\tvalidation_1-rmse:196.666\n",
      "[1300]\tvalidation_0-rmse:162.558\tvalidation_1-rmse:186.234\n",
      "[1400]\tvalidation_0-rmse:152.557\tvalidation_1-rmse:181.217\n",
      "[1500]\tvalidation_0-rmse:144.698\tvalidation_1-rmse:177.254\n",
      "[1600]\tvalidation_0-rmse:138.948\tvalidation_1-rmse:175.128\n",
      "[1700]\tvalidation_0-rmse:132.787\tvalidation_1-rmse:173.665\n",
      "[1800]\tvalidation_0-rmse:128.477\tvalidation_1-rmse:173.064\n",
      "[1900]\tvalidation_0-rmse:124.634\tvalidation_1-rmse:172.594\n",
      "[2000]\tvalidation_0-rmse:121.297\tvalidation_1-rmse:171.883\n",
      "[2100]\tvalidation_0-rmse:118.441\tvalidation_1-rmse:171.081\n",
      "[2200]\tvalidation_0-rmse:115.783\tvalidation_1-rmse:170.947\n",
      "Stopping. Best iteration:\n",
      "[2167]\tvalidation_0-rmse:116.583\tvalidation_1-rmse:170.87\n",
      "\n",
      "0.8069301292432165\n",
      "valid mean: 668.2161\n",
      "true  mean: 673.0143939393939\n",
      "test  mean: 419.4018\n",
      "--------------------------\n",
      "(1320, 2)\n",
      "---\n",
      "(0, 16)\n",
      "windows_var_features start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1320/1320 [00:18<00:00, 69.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows_var_features end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36960, 93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36960, 131)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 27.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxxxxxxxxxxxxxxxxx\n",
      "119 119\n",
      "all_idx  : 9 27\n",
      "train_idx: 9 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "[0]\tvalidation_0-rmse:995.968\tvalidation_1-rmse:1451.31\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:995.439\tvalidation_1-rmse:1450.78\n",
      "[200]\tvalidation_0-rmse:994.013\tvalidation_1-rmse:1449.33\n",
      "[300]\tvalidation_0-rmse:990.205\tvalidation_1-rmse:1445.44\n",
      "[400]\tvalidation_0-rmse:980.3\tvalidation_1-rmse:1435.25\n",
      "[500]\tvalidation_0-rmse:955.975\tvalidation_1-rmse:1409.8\n",
      "[600]\tvalidation_0-rmse:902.264\tvalidation_1-rmse:1351.77\n",
      "[700]\tvalidation_0-rmse:801.78\tvalidation_1-rmse:1237.62\n",
      "[800]\tvalidation_0-rmse:651.434\tvalidation_1-rmse:1058.43\n",
      "[900]\tvalidation_0-rmse:479.185\tvalidation_1-rmse:843.793\n",
      "[1000]\tvalidation_0-rmse:327.634\tvalidation_1-rmse:647.909\n",
      "[1100]\tvalidation_0-rmse:225.623\tvalidation_1-rmse:521.198\n",
      "[1200]\tvalidation_0-rmse:178.625\tvalidation_1-rmse:459.319\n",
      "[1300]\tvalidation_0-rmse:162.548\tvalidation_1-rmse:433.426\n",
      "[1400]\tvalidation_0-rmse:152.602\tvalidation_1-rmse:420.212\n",
      "[1500]\tvalidation_0-rmse:144.758\tvalidation_1-rmse:411.628\n",
      "[1600]\tvalidation_0-rmse:139.1\tvalidation_1-rmse:408.385\n",
      "[1700]\tvalidation_0-rmse:134.35\tvalidation_1-rmse:405.174\n",
      "[1800]\tvalidation_0-rmse:129.32\tvalidation_1-rmse:401.971\n",
      "[1900]\tvalidation_0-rmse:126.114\tvalidation_1-rmse:401.24\n",
      "[2000]\tvalidation_0-rmse:122.507\tvalidation_1-rmse:399.864\n",
      "[2100]\tvalidation_0-rmse:119.492\tvalidation_1-rmse:399.225\n",
      "[2200]\tvalidation_0-rmse:117.406\tvalidation_1-rmse:398.966\n",
      "[2300]\tvalidation_0-rmse:115.326\tvalidation_1-rmse:398.394\n",
      "[2400]\tvalidation_0-rmse:113.404\tvalidation_1-rmse:397.93\n",
      "[2500]\tvalidation_0-rmse:111.387\tvalidation_1-rmse:397.52\n",
      "Stopping. Best iteration:\n",
      "[2447]\tvalidation_0-rmse:112.554\tvalidation_1-rmse:397.319\n",
      "\n",
      "0.7099352441490583\n",
      "valid mean: 773.9361\n",
      "true  mean: 899.8204545454546\n",
      "test  mean: 378.03458\n",
      "--------------------------\n",
      "(1320, 2)\n",
      "---\n",
      "(0, 16)\n"
     ]
    }
   ],
   "source": [
    "for month in [25,26,27,28]: \n",
    "#     judge = month-20\n",
    "    m_type = 'xgb'\n",
    "    data = Cluster(data,month)\n",
    "    data_df = windows_feature(data)\n",
    "    data_df2, stat_feat = get_stat_feature(data_df)\n",
    "    data_df3, stat2_feat = get_stat_feature2(data_df2)\n",
    "    data_df4, stat3_feat = get_stat_feature3(data_df3)\n",
    "\n",
    "    win_feat = ['windows3_var','windows5_var','windows7_var']\n",
    "#     winPop_feat = ['windowsPop4_var','windowsPop4_std','windowsPop5_var','windowsPop5_std','windowsPop12_var','windowsPop12_std']\n",
    "#     ,'windows6_var','windows6_std']\n",
    "#     qushi_feat = ['ratio2','differ2']\n",
    "    num_feat = ['regYear','regMonth'] + stat_feat+stat2_feat+stat3_feat +win_feat#,'windows_var','windows_std'\n",
    "    cate_feat = ['adcode','bodyType','model','model_adcode','body_adcode','cluster_label']\n",
    "\n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df4[i] = data_df4[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df4[i] = lbl.fit_transform(data_df4[i].astype(str))\n",
    "\n",
    "    features = num_feat + cate_feat\n",
    "    print(\"xxxxxxxxxxxxxxxxxx\")\n",
    "    print(len(features), len(set(features)))\n",
    "    sub,val_pred = get_train_model(data_df4, month, m_type)\n",
    "#     online_test_idx  = (data_df4['mt'].between(21  , 24  ))\n",
    "    print(\"---\")\n",
    "    print(data.loc[(data.regMonth==month)].shape)\n",
    "    data.loc[(data.mt==month), 'salesVolume'   ] = sub['forecastVolum'].values\n",
    "    data.loc[(data.mt==(month)), 'label'      ] = sub['forecastVolum'].values\n",
    "    data.loc[(data.mt==(month)), 'pred_label'      ] = sub['forecastVolum'].values\n",
    "#     data['n_label'] = data['label'] / data['model_weight']\n",
    "\n",
    "    # # sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "# # sub.columns = ['id','forecastVolum']\n",
    "# # sub[['id','forecastVolum']].round().astype(int).to_csv('submit/yulao_lgb.csv', index=False)\n",
    "# best_score = online_score(data[online_test_idx]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  forecastVolum\n",
      "31680   1          220.0\n",
      "31681   2          286.0\n",
      "31682   3          131.0\n",
      "31683   4          225.0\n",
      "31684   5          354.0\n",
      "         id  forecastVolum\n",
      "36955  5364           73.0\n",
      "36956  5365           69.0\n",
      "36957  5366           82.0\n",
      "36958  5367          176.0\n",
      "36959  5368           47.0\n"
     ]
    }
   ],
   "source": [
    "sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub.columns = ['id','forecastVolum']\n",
    "print(sub.head())\n",
    "print(sub.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  forecastVolum\n",
      "31680   1          246.0\n",
      "31681   2          309.0\n",
      "31682   3          172.0\n",
      "31683   4          283.0\n",
      "31684   5          376.0\n",
      "         id  forecastVolum\n",
      "36955  5364           99.0\n",
      "36956  5365           94.0\n",
      "36957  5366           92.0\n",
      "36958  5367          216.0\n",
      "36959  5368           65.0\n"
     ]
    }
   ],
   "source": [
    "sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub.columns = ['id','forecastVolum']\n",
    "print(sub.head())\n",
    "print(sub.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  forecastVolum\n",
      "31680   1          279.0\n",
      "31681   2          312.0\n",
      "31682   3          161.0\n",
      "31683   4          295.0\n",
      "31684   5          352.0\n",
      "         id  forecastVolum\n",
      "36955  5364          100.0\n",
      "36956  5365           94.0\n",
      "36957  5366           95.0\n",
      "36958  5367          213.0\n",
      "36959  5368           69.0\n"
     ]
    }
   ],
   "source": [
    "sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub.columns = ['id','forecastVolum']\n",
    "print(sub.head())\n",
    "print(sub.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[['id','forecastVolum']].round().astype(int).to_csv('submit/xgb0929.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 9 20\n",
      "train_idx: 9 16\n",
      "valid_idx: 17 17\n",
      "test_idx : 21 21\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 128712\tvalid_1's l2: 98700.9\n",
      "[200]\ttraining's l2: 41958.5\tvalid_1's l2: 38841.5\n",
      "[300]\ttraining's l2: 23711.2\tvalid_1's l2: 28937.2\n",
      "[400]\ttraining's l2: 17316.6\tvalid_1's l2: 26511.4\n",
      "[500]\ttraining's l2: 13789.8\tvalid_1's l2: 25838.3\n",
      "[600]\ttraining's l2: 11344.6\tvalid_1's l2: 25413.5\n",
      "[700]\ttraining's l2: 9716.53\tvalid_1's l2: 25005.3\n",
      "[800]\ttraining's l2: 8521.85\tvalid_1's l2: 24786.1\n",
      "[900]\ttraining's l2: 7601.14\tvalid_1's l2: 24786.9\n",
      "[1000]\ttraining's l2: 6807.82\tvalid_1's l2: 24710.5\n",
      "[1100]\ttraining's l2: 6154.66\tvalid_1's l2: 24588.3\n",
      "[1200]\ttraining's l2: 5603.01\tvalid_1's l2: 24436.2\n",
      "[1300]\ttraining's l2: 5128.15\tvalid_1's l2: 24299.6\n",
      "[1400]\ttraining's l2: 4756.47\tvalid_1's l2: 24098.7\n",
      "[1500]\ttraining's l2: 4411.44\tvalid_1's l2: 23997.3\n",
      "[1600]\ttraining's l2: 4081.94\tvalid_1's l2: 23915.1\n",
      "[1700]\ttraining's l2: 3801.56\tvalid_1's l2: 23785.2\n",
      "[1800]\ttraining's l2: 3551.93\tvalid_1's l2: 23733.7\n",
      "[1900]\ttraining's l2: 3322.77\tvalid_1's l2: 23685.3\n",
      "[2000]\ttraining's l2: 3105.34\tvalid_1's l2: 23583.8\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's l2: 3105.34\tvalid_1's l2: 23583.8\n",
      "0.7973272983520384\n",
      "valid mean: 497.2429189926641\n",
      "true  mean: 534.5318181818182\n",
      "test  mean: 641.6628984132291\n",
      "(1320, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 9 21\n",
      "train_idx: 9 17\n",
      "valid_idx: 18 18\n",
      "test_idx : 22 22\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 124896\tvalid_1's l2: 101622\n",
      "[200]\ttraining's l2: 41221.5\tvalid_1's l2: 40668.4\n",
      "[300]\ttraining's l2: 23551.2\tvalid_1's l2: 30796.4\n",
      "[400]\ttraining's l2: 17247.5\tvalid_1's l2: 28629.1\n",
      "[500]\ttraining's l2: 13644.1\tvalid_1's l2: 28447.5\n",
      "[600]\ttraining's l2: 11311.3\tvalid_1's l2: 28214.8\n",
      "[700]\ttraining's l2: 9665.8\tvalid_1's l2: 28306.6\n",
      "Early stopping, best iteration is:\n",
      "[602]\ttraining's l2: 11275.5\tvalid_1's l2: 28202.4\n",
      "0.7483585609319627\n",
      "valid mean: 547.3275192104005\n",
      "true  mean: 523.3159090909091\n",
      "test  mean: 648.8015280661291\n",
      "(1320, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 9 22\n",
      "train_idx: 9 18\n",
      "valid_idx: 19 19\n",
      "test_idx : 23 23\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 121129\tvalid_1's l2: 101400\n",
      "[200]\ttraining's l2: 40304.7\tvalid_1's l2: 38675.6\n",
      "[300]\ttraining's l2: 23218.8\tvalid_1's l2: 27340.3\n",
      "[400]\ttraining's l2: 17179.7\tvalid_1's l2: 24853.9\n",
      "[500]\ttraining's l2: 13713.1\tvalid_1's l2: 23959.2\n",
      "[600]\ttraining's l2: 11471.2\tvalid_1's l2: 23400.8\n",
      "[700]\ttraining's l2: 9962.11\tvalid_1's l2: 22931.2\n",
      "[800]\ttraining's l2: 8881.21\tvalid_1's l2: 22567.1\n",
      "[900]\ttraining's l2: 8007.93\tvalid_1's l2: 22383.6\n",
      "[1000]\ttraining's l2: 7299.37\tvalid_1's l2: 22289.3\n",
      "[1100]\ttraining's l2: 6668.06\tvalid_1's l2: 22270.3\n",
      "[1200]\ttraining's l2: 6149.12\tvalid_1's l2: 22150.4\n",
      "Early stopping, best iteration is:\n",
      "[1196]\ttraining's l2: 6170.05\tvalid_1's l2: 22128.1\n",
      "0.7468931536269028\n",
      "valid mean: 560.7094271141314\n",
      "true  mean: 552.2295454545455\n",
      "test  mean: 734.8046071367794\n",
      "(1320, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 9 23\n",
      "train_idx: 9 19\n",
      "valid_idx: 20 20\n",
      "test_idx : 24 24\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 118772\tvalid_1's l2: 145395\n",
      "[200]\ttraining's l2: 39386.3\tvalid_1's l2: 51071.7\n",
      "[300]\ttraining's l2: 22711.1\tvalid_1's l2: 32006.2\n",
      "[400]\ttraining's l2: 17040\tvalid_1's l2: 27020.4\n",
      "[500]\ttraining's l2: 13774.6\tvalid_1's l2: 25125.4\n",
      "[600]\ttraining's l2: 11675.5\tvalid_1's l2: 24421\n",
      "[700]\ttraining's l2: 10208\tvalid_1's l2: 24129.7\n",
      "[800]\ttraining's l2: 9205.22\tvalid_1's l2: 23964.6\n",
      "[900]\ttraining's l2: 8388.5\tvalid_1's l2: 23799.9\n",
      "[1000]\ttraining's l2: 7727.56\tvalid_1's l2: 23768.7\n",
      "Early stopping, best iteration is:\n",
      "[989]\ttraining's l2: 7801.96\tvalid_1's l2: 23734.8\n",
      "0.7917019686244774\n",
      "valid mean: 595.4352742803294\n",
      "true  mean: 620.0212121212121\n",
      "test  mean: 856.408786058386\n",
      "(1320, 2)\n"
     ]
    }
   ],
   "source": [
    "for month in [21,22,23,24]: \n",
    "    m_type = 'lgb' \n",
    "    \n",
    "    data_df, stat_feat = get_stat_feature(data)\n",
    "    \n",
    "    num_feat = ['regYear','regMonth'] + stat_feat\n",
    "    cate_feat = ['adcode','bodyType','model']\n",
    "    \n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "           \n",
    "    features = num_feat + cate_feat\n",
    "#     print(len(features), len(set(features)))   \n",
    "    \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type)   \n",
    "    data.loc[(data.mt==month), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.mt==month), 'label'      ] = sub['forecastVolum'].values\n",
    "    data.loc[(data.mt==(month)), 'pred_label'      ] = sub['forecastVolum'].values\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "# sub.columns = ['id','forecastVolum']\n",
    "# sub[['id','forecastVolum']].round().astype(int).to_csv('CCF_sales.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 86584.9\tvalid_1's l2: 151719\n",
      "[200]\ttraining's l2: 27784.3\tvalid_1's l2: 71704.5\n",
      "[300]\ttraining's l2: 14902.5\tvalid_1's l2: 57361.3\n",
      "[400]\ttraining's l2: 10243.5\tvalid_1's l2: 52224.7\n",
      "[500]\ttraining's l2: 7869.38\tvalid_1's l2: 50304.7\n",
      "[600]\ttraining's l2: 6385.06\tvalid_1's l2: 49569.7\n",
      "[700]\ttraining's l2: 5380.65\tvalid_1's l2: 48911.9\n",
      "[800]\ttraining's l2: 4634.41\tvalid_1's l2: 48274\n",
      "[900]\ttraining's l2: 4071.47\tvalid_1's l2: 48026.2\n",
      "[1000]\ttraining's l2: 3625\tvalid_1's l2: 47641.9\n",
      "[1100]\ttraining's l2: 3253.2\tvalid_1's l2: 47425.4\n",
      "[1200]\ttraining's l2: 2928.61\tvalid_1's l2: 47143.3\n",
      "[1300]\ttraining's l2: 2653.04\tvalid_1's l2: 46870.8\n",
      "[1400]\ttraining's l2: 2414.07\tvalid_1's l2: 46669.9\n",
      "[1500]\ttraining's l2: 2207.68\tvalid_1's l2: 46487.6\n",
      "[1600]\ttraining's l2: 2028.06\tvalid_1's l2: 46336.7\n",
      "[1700]\ttraining's l2: 1876.96\tvalid_1's l2: 46208.4\n",
      "[1800]\ttraining's l2: 1749.37\tvalid_1's l2: 46176.2\n",
      "[1900]\ttraining's l2: 1632.35\tvalid_1's l2: 46079.2\n",
      "[2000]\ttraining's l2: 1525.02\tvalid_1's l2: 46029.5\n",
      "[2100]\ttraining's l2: 1420.06\tvalid_1's l2: 45984.2\n",
      "[2200]\ttraining's l2: 1322.58\tvalid_1's l2: 45885.2\n",
      "Early stopping, best iteration is:\n",
      "[2188]\ttraining's l2: 1333.16\tvalid_1's l2: 45878\n",
      "0.7657263463789578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 90083.5\tvalid_1's l2: 118412\n",
      "[200]\ttraining's l2: 28475.8\tvalid_1's l2: 59906.1\n",
      "[300]\ttraining's l2: 15309.6\tvalid_1's l2: 52080.3\n",
      "[400]\ttraining's l2: 10785.7\tvalid_1's l2: 50404.3\n",
      "[500]\ttraining's l2: 8324.54\tvalid_1's l2: 49632.1\n",
      "[600]\ttraining's l2: 6828.3\tvalid_1's l2: 49046.4\n",
      "[700]\ttraining's l2: 5813.9\tvalid_1's l2: 48997.8\n",
      "Early stopping, best iteration is:\n",
      "[648]\ttraining's l2: 6301.83\tvalid_1's l2: 48762.4\n",
      "0.7352932759641437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 93591.6\tvalid_1's l2: 135289\n",
      "[200]\ttraining's l2: 29582.9\tvalid_1's l2: 52574.8\n",
      "[300]\ttraining's l2: 15864.8\tvalid_1's l2: 39181.2\n",
      "[400]\ttraining's l2: 11154.7\tvalid_1's l2: 36023.5\n",
      "[500]\ttraining's l2: 8739.67\tvalid_1's l2: 35331.5\n",
      "[600]\ttraining's l2: 7173.39\tvalid_1's l2: 34526.5\n",
      "[700]\ttraining's l2: 6126.06\tvalid_1's l2: 34402.5\n",
      "[800]\ttraining's l2: 5347.97\tvalid_1's l2: 34349\n",
      "[900]\ttraining's l2: 4770.82\tvalid_1's l2: 34426\n",
      "Early stopping, best iteration is:\n",
      "[806]\ttraining's l2: 5308.31\tvalid_1's l2: 34325.1\n",
      "0.7811424903161602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 96023.9\tvalid_1's l2: 552065\n",
      "[200]\ttraining's l2: 29709.3\tvalid_1's l2: 354551\n",
      "[300]\ttraining's l2: 16067.9\tvalid_1's l2: 299015\n",
      "[400]\ttraining's l2: 11490.5\tvalid_1's l2: 282547\n",
      "[500]\ttraining's l2: 9067.98\tvalid_1's l2: 274322\n",
      "[600]\ttraining's l2: 7522.51\tvalid_1's l2: 271372\n",
      "[700]\ttraining's l2: 6477.28\tvalid_1's l2: 271395\n",
      "Early stopping, best iteration is:\n",
      "[658]\ttraining's l2: 6879.88\tvalid_1's l2: 270441\n",
      "0.6226761089064834\n"
     ]
    }
   ],
   "source": [
    "for month in [21,22,23,24]: \n",
    "    m_type = 'lgb' \n",
    "    \n",
    "    data_df, stat_feat = get_stat_feature(data)\n",
    "    \n",
    "    num_feat = ['regYear','regMonth','popularity'] + stat_feat\n",
    "    cate_feat = ['adcode','bodyType','model']\n",
    "    \n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "           \n",
    "    features = num_feat + cate_feat\n",
    "#     print(len(features), len(set(features)))   \n",
    "    \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type)   \n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'label'      ] = sub['forecastVolum'].values\n",
    "#     data.loc[(data.mt==(month)), 'pred_label'      ] = sub['forecastVolum'].values\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub.columns = ['id','forecastVolum']\n",
    "# sub[['id','forecastVolum']].round().astype(int).to_csv('CCF_sales.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[['id','forecastVolum']].round().astype(int).to_csv('CCF_sales0914.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 7291.26\tvalid_1's l2: 37932.3\n",
      "[200]\ttraining's l2: 3715.93\tvalid_1's l2: 35716.9\n",
      "[300]\ttraining's l2: 2515.27\tvalid_1's l2: 35194.8\n",
      "[400]\ttraining's l2: 1831.38\tvalid_1's l2: 34788.8\n",
      "[500]\ttraining's l2: 1397.64\tvalid_1's l2: 34608.6\n",
      "[600]\ttraining's l2: 1065.51\tvalid_1's l2: 34527.1\n",
      "[700]\ttraining's l2: 849.095\tvalid_1's l2: 34415.2\n",
      "[800]\ttraining's l2: 679.238\tvalid_1's l2: 34333.1\n",
      "[900]\ttraining's l2: 545.247\tvalid_1's l2: 34326.4\n",
      "Early stopping, best iteration is:\n",
      "[838]\ttraining's l2: 624.086\tvalid_1's l2: 34316.6\n",
      "0.7559303097480222\n",
      "valid mean: 602.8972278482273\n",
      "true  mean: 649.3121212121212\n",
      "test  mean: 493.9801201875369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 7936.91\tvalid_1's l2: 41558.5\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's l2: 10761.5\tvalid_1's l2: 41117.3\n",
      "0.7414955122487169\n",
      "valid mean: 623.4500376146684\n",
      "true  mean: 616.5537878787878\n",
      "test  mean: 324.6451813135614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 8653.84\tvalid_1's l2: 32560.4\n",
      "[200]\ttraining's l2: 4627.91\tvalid_1's l2: 32133.2\n",
      "Early stopping, best iteration is:\n",
      "[155]\ttraining's l2: 5757.15\tvalid_1's l2: 31853.4\n",
      "0.7794578141087838\n",
      "valid mean: 639.6227869473659\n",
      "true  mean: 673.0143939393939\n",
      "test  mean: 479.55100257280156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 9306.24\tvalid_1's l2: 302435\n",
      "[200]\ttraining's l2: 5107.21\tvalid_1's l2: 292129\n",
      "[300]\ttraining's l2: 3583.18\tvalid_1's l2: 289373\n",
      "[400]\ttraining's l2: 2709.06\tvalid_1's l2: 288389\n",
      "[500]\ttraining's l2: 2162.77\tvalid_1's l2: 287983\n",
      "[600]\ttraining's l2: 1746.75\tvalid_1's l2: 287504\n",
      "[700]\ttraining's l2: 1446.22\tvalid_1's l2: 287029\n",
      "[800]\ttraining's l2: 1196.94\tvalid_1's l2: 286429\n",
      "[900]\ttraining's l2: 1008.26\tvalid_1's l2: 286030\n",
      "Early stopping, best iteration is:\n",
      "[856]\ttraining's l2: 1089.91\tvalid_1's l2: 286004\n",
      "0.588139278724323\n",
      "valid mean: 645.3917897243205\n",
      "true  mean: 899.8204545454546\n",
      "test  mean: 468.0356962498267\n"
     ]
    }
   ],
   "source": [
    "for month in [25,26,27,28]: \n",
    "    m_type = 'lgb' \n",
    "    \n",
    "    data_df, stat_feat = get_stat_feature(data)\n",
    "    \n",
    "    num_feat = ['regYear'] + stat_feat\n",
    "    cate_feat = ['adcode','bodyType','model','regMonth']\n",
    "    \n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "           \n",
    "    features = num_feat + cate_feat\n",
    "    print(len(features), len(set(features)))   \n",
    "    \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type)   \n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'label'      ] = sub['forecastVolum'].values\n",
    "sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub.columns = ['id','forecastVolum']\n",
    "# sub[['id','forecastVolum']].round().astype(int).to_csv('CCF_sales.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
